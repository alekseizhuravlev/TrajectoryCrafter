{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load all TensorBoard data once\n",
    "base_path = \"/home/azhuravl/scratch/mlp_probes/tensorboard\"\n",
    "tensorboard_data = {}\n",
    "\n",
    "print(\"Loading TensorBoard data...\")\n",
    "base_path = Path(base_path)\n",
    "\n",
    "tb_files = list(base_path.rglob(\"events.out.tfevents.*\"))\n",
    "for event_file in tqdm(tb_files):\n",
    "    # Extract hyperparameters from path\n",
    "    path_parts = event_file.parts\n",
    "    \n",
    "    # Find timestep and layer name from path structure\n",
    "    timestep = None\n",
    "    layer_name = None\n",
    "    \n",
    "    # Look for timestep_X pattern\n",
    "    for i, part in enumerate(path_parts):\n",
    "        if part.startswith('timestep_'):\n",
    "            timestep = int(part.split('_')[1])\n",
    "            # The next folder should be the layer name\n",
    "            if i + 1 < len(path_parts):\n",
    "                layer_name = path_parts[i + 1]\n",
    "            break\n",
    "    \n",
    "    if timestep is None or layer_name is None:\n",
    "        continue\n",
    "    \n",
    "    # Load tensorboard data\n",
    "    try:\n",
    "        ea = EventAccumulator(str(event_file.parent))\n",
    "        ea.Reload()\n",
    "        \n",
    "        # Store the event accumulator with metadata\n",
    "        key = (timestep, layer_name)\n",
    "        tensorboard_data[key] = {\n",
    "            'accumulator': ea,\n",
    "            'timestep': timestep,\n",
    "            'layer_name': layer_name,\n",
    "            'path': str(event_file.parent)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {event_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Loaded {len(tensorboard_data)} experiments\")\n",
    "print(f\"Available configurations: {list(tensorboard_data.keys())}\")\n",
    "\n",
    "# Analyze the available timesteps and layer names\n",
    "timesteps = set()\n",
    "layer_names = set()\n",
    "\n",
    "for (timestep, layer_name) in tensorboard_data.keys():\n",
    "    timesteps.add(timestep)\n",
    "    layer_names.add(layer_name)\n",
    "\n",
    "print(f\"Available timesteps: {sorted(timesteps)}\")\n",
    "print(f\"Available layer names: {sorted(layer_names)}\")\n",
    "\n",
    "# Check what metrics are available across all experiments\n",
    "all_metrics = set()\n",
    "for config, data in tensorboard_data.items():\n",
    "    scalar_tags = data['accumulator'].Tags()['scalars']\n",
    "    all_metrics.update(scalar_tags)\n",
    "\n",
    "print(f\"Available metrics across all experiments: {sorted(all_metrics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_multiple_metrics(tensorboard_data, metric_names, exact_match=False):\n",
    "    \"\"\"\n",
    "    Extract multiple metrics from all loaded TensorBoard data.\n",
    "    \n",
    "    Args:\n",
    "        tensorboard_data: Dictionary of loaded TensorBoard data\n",
    "        metric_names: List of metric names to extract\n",
    "        exact_match: If False, does case-insensitive substring matching\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: timestep, layer_name, metric_name, metric_value, step, wall_time\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for (timestep, layer_name), data in tensorboard_data.items():\n",
    "        ea = data['accumulator']\n",
    "        scalar_tags = ea.Tags()['scalars']\n",
    "        \n",
    "        for metric_name in metric_names:\n",
    "            # Find the metric\n",
    "            target_tag = None\n",
    "            if exact_match:\n",
    "                target_tag = metric_name if metric_name in scalar_tags else None\n",
    "            else:\n",
    "                # Case insensitive substring search\n",
    "                for tag in scalar_tags:\n",
    "                    if metric_name.lower() in tag.lower():\n",
    "                        target_tag = tag\n",
    "                        break\n",
    "            \n",
    "            if target_tag:\n",
    "                scalar_events = ea.Scalars(target_tag)\n",
    "                \n",
    "                for event in scalar_events:\n",
    "                    results.append({\n",
    "                        'timestep': timestep,\n",
    "                        'layer_name': layer_name,\n",
    "                        'metric_name': metric_name,\n",
    "                        # 'actual_tag': target_tag,\n",
    "                        'metric_value': event.value,\n",
    "                        # 'step': event.step,\n",
    "                        # 'wall_time': event.wall_time\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"Metric '{metric_name}' not found for config ({timestep}, {layer_name})\")\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Extract multiple metrics\n",
    "metrics_to_extract = ['final_test_rel_error', \n",
    "                      'final_train_rel_error', \n",
    "                      'generalization_gap_rel_error', \n",
    "                      ]\n",
    "df = extract_multiple_metrics(tensorboard_data, metrics_to_extract)\n",
    "\n",
    "# Save to CSV\n",
    "# df.to_csv('tensorboard_metrics.csv', index=False)\n",
    "print(f\"Extracted {len(df)} data points across {len(metrics_to_extract)} metrics\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order = [\n",
    "    'pos_embed',\n",
    "    'cross_attn_0',\n",
    "    'transformer_block_8',\n",
    "    'cross_attn_1',\n",
    "    'transformer_block_16',\n",
    "    'transformer_block_24',\n",
    "    'cross_attn_2',\n",
    "    'transformer_block_32',\n",
    "    'transformer_block_40',\n",
    "    'final_norm',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_single_metric(tensorboard_data, metric_name, exact_match=False):\n",
    "    \"\"\"\n",
    "    Extract a single metric from all loaded TensorBoard data.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for (timestep, layer_name), data in tensorboard_data.items():\n",
    "        ea = data['accumulator']\n",
    "        scalar_tags = ea.Tags()['scalars']\n",
    "        \n",
    "        # Find the metric\n",
    "        target_tag = None\n",
    "        if exact_match:\n",
    "            target_tag = metric_name if metric_name in scalar_tags else None\n",
    "        else:\n",
    "            # Case insensitive substring search\n",
    "            for tag in scalar_tags:\n",
    "                if metric_name.lower() in tag.lower():\n",
    "                    target_tag = tag\n",
    "                    break\n",
    "        \n",
    "        if target_tag:\n",
    "            scalar_events = ea.Scalars(target_tag)\n",
    "            # Get the final value (last step)\n",
    "            if scalar_events:\n",
    "                final_event = scalar_events[-1]\n",
    "                results.append({\n",
    "                    'timestep': timestep,\n",
    "                    'layer_name': layer_name,\n",
    "                    'metric_value': final_event.value,\n",
    "                    'step': final_event.step,\n",
    "                    'actual_tag': target_tag\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Extract the metric\n",
    "metric_df = extract_single_metric(tensorboard_data, 'final_test_rel_error')\n",
    "\n",
    "# Filter to only include layers that are in our defined order\n",
    "metric_df = metric_df[metric_df['layer_name'].isin(layer_order)]\n",
    "\n",
    "# Get unique timesteps in sorted order\n",
    "timesteps = sorted(metric_df['timestep'].unique())\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Color palette for different timesteps\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(timesteps)))\n",
    "\n",
    "for i, timestep in enumerate(timesteps):\n",
    "    # Filter data for this timestep\n",
    "    timestep_data = metric_df[metric_df['timestep'] == timestep]\n",
    "    \n",
    "    # Create ordered data according to layer_order\n",
    "    ordered_values = []\n",
    "    ordered_layers = []\n",
    "    \n",
    "    for layer in layer_order:\n",
    "        layer_data = timestep_data[timestep_data['layer_name'] == layer]\n",
    "        if not layer_data.empty:\n",
    "            ordered_values.append(layer_data['metric_value'].iloc[0])\n",
    "            ordered_layers.append(layer)\n",
    "    \n",
    "    # Plot the line\n",
    "    if ordered_values:\n",
    "        plt.plot(range(len(ordered_layers)), ordered_values, \n",
    "                marker='o', markersize=8, linewidth=2, \n",
    "                label=f'Timestep {timestep}', color=colors[i])\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Layer', fontsize=12)\n",
    "plt.ylabel('Depth Relative Error (%) on Test Set', fontsize=12)\n",
    "plt.title('Linear Probing Across Layers by Timestep\\n Monkaa dataset, 200 train, 50 test samples', fontsize=14)\n",
    "plt.xticks(range(len(layer_order)), layer_order, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary of final_test_rel_error by timestep and layer:\")\n",
    "summary = metric_df.pivot(index='layer_name', columns='timestep', values='metric_value')\n",
    "# Reorder rows according to layer_order\n",
    "summary = summary.reindex(layer_order)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r /home/azhuravl/scratch/SceneFlow/Monkaa/monkaa__frames_cleanpass.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/azhuravl/scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
