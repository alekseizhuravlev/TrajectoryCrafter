{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Path Setup\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"/home/azhuravl/work/TrajectoryCrafter\")\n",
    "# os.chdir(trajcrafter_path)\n",
    "\n",
    "import inference_orbits\n",
    "\n",
    "sys.path.insert(0, \"/home/azhuravl/work/TrajectoryCrafter/notebooks/28_08_25_trajectories\")\n",
    "\n",
    "import core, trajectory_generation, viser_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload core, trajectory_generation, viser_utils with importlib\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(core)\n",
    "importlib.reload(trajectory_generation)\n",
    "importlib.reload(viser_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Argument Setup\n",
    "# Create opts manually for notebook use\n",
    "parser = inference_orbits.get_parser()\n",
    "opts_base = parser.parse_args([\n",
    "    '--video_path', './test/videos/0-NNvgaTcVzAG0-r.mp4',  # Change this path\n",
    "    '--radius', '1.0',\n",
    "    '--device', 'cuda:0'\n",
    "])\n",
    "\n",
    "# Set common parameters\n",
    "opts_base.weight_dtype = torch.bfloat16\n",
    "opts_base.camera = \"target\"\n",
    "opts_base.mode = \"gradual\"\n",
    "opts_base.mask = True\n",
    "opts_base.target_pose = [0, 90, opts_base.radius, 0, 0]  # right_90 example\n",
    "opts_base.exp_name = f\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Cell 4: Run Visualization\n",
    "# Initialize visualization TrajCrafter\n",
    "print(\"Initializing TrajCrafter for visualization...\")\n",
    "vis_crafter = core.TrajCrafterVisualization(opts_base)\n",
    "\n",
    "# Extract scene data\n",
    "print(\"Extracting scene data...\")\n",
    "scene_data = vis_crafter.extract_scene_data(opts_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create warper for 3D point extraction\n",
    "print(\"Creating 3D point cloud from all frames...\")\n",
    "vis_warper = core.VisualizationWarper(device=opts_base.device)\n",
    "\n",
    "# Extract points from all frames\n",
    "all_points_3d = []\n",
    "all_colors_rgb = []\n",
    "\n",
    "warped_images = []\n",
    "masks = []\n",
    "\n",
    "num_frames = scene_data['frames_tensor'].shape[0]\n",
    "for i in tqdm(range(num_frames), desc=\"Processing frames\"):\n",
    "    frame_data = {\n",
    "        'frame': scene_data['frames_tensor'][i:i+1],\n",
    "        'depth': scene_data['depths'][i:i+1], \n",
    "        'pose_source': scene_data['pose_source'][i:i+1],\n",
    "        'intrinsics': scene_data['intrinsics'][i:i+1],\n",
    "    }\n",
    "    \n",
    "    points_3d_frame, colors_rgb_frame = vis_warper.extract_3d_points_with_colors(\n",
    "        frame_data['frame'],\n",
    "        frame_data['depth'], \n",
    "        frame_data['pose_source'],\n",
    "        frame_data['intrinsics'],\n",
    "        subsample_step=20  # Increased for performance with multiple frames\n",
    "    )\n",
    "    \n",
    "    if points_3d_frame.shape[0] > 0:  # Only add if we have valid points\n",
    "        all_points_3d.append(points_3d_frame)\n",
    "        all_colors_rgb.append(colors_rgb_frame)\n",
    "        \n",
    "        \n",
    "    warped_frame2, mask2, warped_depth2, flow12 = vis_warper.forward_warp(\n",
    "        scene_data['frames_tensor'][i:i+1],\n",
    "        None,\n",
    "        scene_data['depths'][i:i+1],\n",
    "        scene_data['pose_source'][i:i+1],\n",
    "        scene_data['pose_target'][i:i+1],\n",
    "        scene_data['intrinsics'][i:i+1],\n",
    "        None,\n",
    "        opts_base.mask,\n",
    "        twice=False,\n",
    "    )\n",
    "    warped_images.append(warped_frame2)\n",
    "    masks.append(mask2)\n",
    "\n",
    "# Concatenate all points\n",
    "if all_points_3d:\n",
    "    points_3d = torch.cat(all_points_3d, dim=0)\n",
    "    colors_rgb = torch.cat(all_colors_rgb, dim=0)\n",
    "    print(f\"Generated {points_3d.shape[0]} 3D points from {len(all_points_3d)} frames\")\n",
    "else:\n",
    "    print(\"No valid 3D points extracted!\")\n",
    "    points_3d = None\n",
    "    colors_rgb = None\n",
    "\n",
    "print(f\"Camera trajectory: {scene_data['pose_target'].shape[0]} poses\")\n",
    "\n",
    "\n",
    "cond_video = (torch.cat(warped_images) + 1.0) / 2.0\n",
    "cond_masks = torch.cat(masks)\n",
    "\n",
    "cond_video = F.interpolate(\n",
    "    cond_video, size=opts_base.sample_size, mode='bilinear', align_corners=False\n",
    ")\n",
    "cond_masks = F.interpolate(cond_masks, size=opts_base.sample_size, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.utils as utils\n",
    "\n",
    "utils.save_video(\n",
    "    cond_video.permute(0, 2, 3, 1),\n",
    "    os.path.join('/home/azhuravl/work/TrajectoryCrafter/notebooks/28_08_25_trajectories/render.mp4'),\n",
    "    fps=opts_base.fps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Create Viser Server (run once)\n",
    "import viser\n",
    "\n",
    "# Check if server already exists and stop it\n",
    "try:\n",
    "    if 'viser_server' in globals() and viser_server is not None:\n",
    "        print(\"Stopping existing server...\")\n",
    "        viser_server.stop()\n",
    "        del viser_server\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create new server\n",
    "print(\"Creating new Viser server on port 8080...\")\n",
    "viser_server = viser.ViserServer(port=8080)\n",
    "print(\"Server started successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scene\n",
    "viser_utils.setup_viser_scene(viser_server, scene_data)\n",
    "\n",
    "# Show first frame\n",
    "viser_utils.animate_frame(viser_server, vis_warper, scene_data, 0)\n",
    "\n",
    "# Add controls\n",
    "viser_utils.add_animation_controls(viser_server, vis_warper, scene_data)\n",
    "viser_utils.add_point_size_control(viser_server, points_3d, colors_rgb)\n",
    "viser_utils.add_camera_controls(viser_server)\n",
    "viser_utils.add_trajectory_controls(viser_server, scene_data, vis_crafter, opts_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = scene_data['pose_target'].clone()\n",
    "\n",
    "# get z translation of 1st frame\n",
    "z_translation = positions[0, 2, 3].item()\n",
    "print(f\"Z translation of 1st frame: {z_translation}\")\n",
    "\n",
    "# subtract z translation from all frames\n",
    "positions[:, 2, 3] -= z_translation\n",
    "\n",
    "# # Create transformation matrix to swap X and Z axes\n",
    "swap_matrix = torch.tensor([\n",
    "    [0, 0, 1, 0],  # New X = old Z\n",
    "    [0, 1, 0, 0],  # New Y = old Y (unchanged)\n",
    "    [1, 0, 0, 0],  # New Z = old X\n",
    "    [0, 0, 0, 1]   # Homogeneous coordinate\n",
    "], dtype=positions.dtype, device=positions.device)\n",
    "\n",
    "# Apply the transformation to all camera matrices\n",
    "positions_swapped = torch.matmul(swap_matrix, positions)\n",
    "\n",
    "positions_swapped[:, 2, 3] += z_translation\n",
    "\n",
    "\n",
    "scene_data_new = copy.deepcopy(scene_data)\n",
    "scene_data_new['pose_target'] = positions_swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = scene_data['pose_target'].clone()\n",
    "\n",
    "# Swap only the translation components (positions)\n",
    "positions_swapped = positions.clone()\n",
    "positions_swapped[:, 0, 3] = positions[:, 2, 3]  # New X = old Z\n",
    "positions_swapped[:, 2, 3] = positions[:, 0, 3]  # New Z = old X\n",
    "# Y position stays the same: positions_swapped[:, 1, 3] = positions[:, 1, 3]\n",
    "\n",
    "scene_data_new = copy.deepcopy(scene_data)\n",
    "scene_data_new['pose_target'] = positions_swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positions[0])\n",
    "print(positions_swapped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positions[0])\n",
    "print(positions_swapped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viser_utils.update_trajectory_visualization(viser_server, scene_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get camera positions from 4x4 matrices\n",
    "# scene_data['pose_target']\n",
    "\n",
    "positions = scene_data['pose_target'][:, :3, 3]\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using maplotlib, plot the 0th and 2rd axis\n",
    "# Using matplotlib, plot the 0th and 2nd axis of positions variable\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot X vs Z (0th vs 2nd axis)\n",
    "plt.plot(positions[:, 0], positions[:, 2], 'b-o', linewidth=2, markersize=4)\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Z Position') \n",
    "plt.title('Camera Trajectory: X vs Z (Top-down view)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "\n",
    "# Mark start and end points\n",
    "plt.plot(positions[0, 0], positions[0, 2], 'go', markersize=10, label='Start')\n",
    "plt.plot(positions[-1, 0], positions[-1, 2], 'ro', markersize=10, label='End')\n",
    "\n",
    "# Add frame numbers for reference\n",
    "for i in range(0, len(positions), max(1, len(positions)//8)):\n",
    "    plt.annotate(f'{i}', (positions[i, 0], positions[i, 2]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the trajectory values\n",
    "print(f\"Trajectory shape: {positions.shape}\")\n",
    "print(f\"X range: {positions[:, 0].min():.3f} to {positions[:, 0].max():.3f}\")\n",
    "print(f\"Z range: {positions[:, 2].min():.3f} to {positions[:, 2].max():.3f}\")\n",
    "print(f\"Start (X,Z): ({positions[0, 0]:.3f}, {positions[0, 2]:.3f})\")\n",
    "print(f\"End (X,Z): ({positions[-1, 0]:.3f}, {positions[-1, 2]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Camera trajectory visualization\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract scene data (same as your existing code)\n",
    "scene_data = vis_crafter.extract_scene_data(opts_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate different circular motions\n",
    "# horizontal_circle = generate_circular_scene_data(vis_crafter, opts_base, scene_data, 'horizontal')\n",
    "vertical_circle = generate_circular_scene_data(vis_crafter, opts_base, scene_data, 'vertical_xz')\n",
    "\n",
    "# Use in your existing Viser visualization\n",
    "# update_trajectory_visualization(viser_server, horizontal_circle)\n",
    "update_trajectory_visualization(viser_server, vertical_circle)\n",
    "\n",
    "print(\"Circular trajectories generated!\")\n",
    "print(\"Available types: horizontal, vertical_xz, vertical_yz, tilted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and print trajectory numbers for a few presets\n",
    "target_poses = {\n",
    "    \"Right 90°\": [0, 90, 1, 0, 0],\n",
    "    \"Full Circle\": [0, 360, 1, 0, 0],\n",
    "    \"Pull Back\": [0, 0, 3, 0, 0]\n",
    "}\n",
    "\n",
    "new_data = generate_new_trajectory(\n",
    "    vis_crafter, opts_base,\n",
    "    target_poses[\"Right 90°\"],\n",
    "    scene_data\n",
    "    )\n",
    "\n",
    "positions = new_data['pose_target'].cpu().numpy()[:, :3, 3]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
