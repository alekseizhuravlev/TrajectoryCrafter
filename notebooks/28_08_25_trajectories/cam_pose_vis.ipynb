{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Path Setup\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add TrajectoryCrafter to Python path\n",
    "trajcrafter_path = \"/home/azhuravl/work/TrajectoryCrafter\"\n",
    "sys.path.insert(0, trajcrafter_path)\n",
    "\n",
    "# Change working directory to TrajectoryCrafter\n",
    "os.chdir(trajcrafter_path)\n",
    "\n",
    "# Now import TrajectoryCrafter modules\n",
    "from demo import TrajCrafter\n",
    "from models.utils import Warper, read_video_frames\n",
    "from models.infer import DepthCrafterDemo\n",
    "import inference_orbits\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Argument Setup\n",
    "# Create opts manually for notebook use\n",
    "parser = inference_orbits.get_parser()\n",
    "opts_base = parser.parse_args([\n",
    "    '--video_path', './test/videos/0-NNvgaTcVzAG0-r.mp4',  # Change this path\n",
    "    '--radius', '1.0',\n",
    "    '--device', 'cuda:0'\n",
    "])\n",
    "\n",
    "# Set common parameters\n",
    "opts_base.weight_dtype = torch.bfloat16\n",
    "opts_base.camera = \"target\"\n",
    "opts_base.mode = \"gradual\"\n",
    "opts_base.mask = True\n",
    "opts_base.target_pose = [0, 90, opts_base.radius, 0, 0]  # right_90 example\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "video_basename = os.path.splitext(os.path.basename(opts_base.video_path))[0]\n",
    "opts_base.exp_name = f\"{video_basename}_{timestamp}_vis\"\n",
    "\n",
    "print(f\"Video: {opts_base.video_path}\")\n",
    "print(f\"Target pose: {opts_base.target_pose}\")\n",
    "print(f\"Device: {opts_base.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Visualization Classes\n",
    "class VisualizationWarper(Warper):\n",
    "    \"\"\"Extended Warper class for 3D visualization\"\"\"\n",
    "    \n",
    "    def extract_3d_points_with_colors(\n",
    "        self,\n",
    "        frame1: torch.Tensor,\n",
    "        depth1: torch.Tensor,\n",
    "        transformation1: torch.Tensor,\n",
    "        intrinsic1: torch.Tensor,\n",
    "        subsample_step: int = 10\n",
    "    ):\n",
    "        \"\"\"Extract 3D world points and their corresponding colors for visualization\"\"\"\n",
    "        b, c, h, w = frame1.shape\n",
    "        \n",
    "        # Move tensors to device\n",
    "        frame1 = frame1.to(self.device).to(self.dtype)\n",
    "        depth1 = depth1.to(self.device).to(self.dtype)\n",
    "        transformation1 = transformation1.to(self.device).to(self.dtype)\n",
    "        intrinsic1 = intrinsic1.to(self.device).to(self.dtype)\n",
    "        \n",
    "        # Create subsampled pixel coordinates for performance\n",
    "        x_coords = torch.arange(0, w, subsample_step, dtype=torch.float32)\n",
    "        y_coords = torch.arange(0, h, subsample_step, dtype=torch.float32)\n",
    "        x2d, y2d = torch.meshgrid(x_coords, y_coords, indexing='xy')\n",
    "        x2d = x2d.to(depth1.device)\n",
    "        y2d = y2d.to(depth1.device)\n",
    "        ones_2d = torch.ones_like(x2d)\n",
    "        \n",
    "        # Stack into homogeneous coordinates\n",
    "        pos_vectors_homo = torch.stack([x2d, y2d, ones_2d], dim=2)[None, :, :, :, None]\n",
    "        \n",
    "        # Subsample depth and colors\n",
    "        depth_sub = depth1[:, 0, ::subsample_step, ::subsample_step]\n",
    "        colors_sub = frame1[:, :, ::subsample_step, ::subsample_step]\n",
    "        \n",
    "        # Unproject to 3D camera coordinates\n",
    "        intrinsic1_inv = torch.linalg.inv(intrinsic1)\n",
    "        intrinsic1_inv_4d = intrinsic1_inv[:, None, None]\n",
    "        depth_4d = depth_sub[:, :, :, None, None]\n",
    "        \n",
    "        unnormalized_pos = torch.matmul(intrinsic1_inv_4d, pos_vectors_homo)\n",
    "        camera_points = depth_4d * unnormalized_pos\n",
    "        \n",
    "        # Transform to world coordinates\n",
    "        ones_4d = torch.ones(b, camera_points.shape[1], camera_points.shape[2], 1, 1).to(depth1)\n",
    "        world_points_homo = torch.cat([camera_points, ones_4d], dim=3)\n",
    "        trans_4d = transformation1[:, None, None]\n",
    "        world_points_homo = torch.matmul(trans_4d, world_points_homo)\n",
    "        world_points = world_points_homo[:, :, :, :3, 0]  # (b, h_sub, w_sub, 3)\n",
    "        \n",
    "        # Prepare colors\n",
    "        colors = colors_sub.permute(0, 2, 3, 1)  # (b, h_sub, w_sub, 3)\n",
    "        \n",
    "        # Filter valid points (positive depth)\n",
    "        valid_mask = depth_sub > 0  # (b, h_sub, w_sub)\n",
    "        \n",
    "        # Flatten and filter\n",
    "        points_3d = world_points[valid_mask]  # (N, 3)\n",
    "        colors_rgb = colors[valid_mask]       # (N, 3)\n",
    "        \n",
    "        return points_3d, colors_rgb\n",
    "\n",
    "\n",
    "class TrajCrafterVisualization(TrajCrafter):\n",
    "    \"\"\"Lightweight TrajCrafter subclass for camera trajectory visualization\"\"\"\n",
    "    \n",
    "    def __init__(self, opts):\n",
    "        # Only initialize what we need for pose generation and depth estimation\n",
    "        self.device = opts.device\n",
    "        self.depth_estimater = DepthCrafterDemo(\n",
    "            unet_path=opts.unet_path,\n",
    "            pre_train_path=opts.pre_train_path,\n",
    "            cpu_offload=opts.cpu_offload,\n",
    "            device=opts.device,\n",
    "        )\n",
    "        print(\"TrajCrafterVisualization initialized (diffusion pipeline skipped)\")\n",
    "    \n",
    "    def extract_scene_data(self, opts):\n",
    "        \"\"\"Extract all data needed for 3D visualization\"\"\"\n",
    "        print(\"Reading video frames...\")\n",
    "        frames = read_video_frames(\n",
    "            opts.video_path, opts.video_length, opts.stride, opts.max_res\n",
    "        )\n",
    "        \n",
    "        print(\"Estimating depth...\")\n",
    "        depths = self.depth_estimater.infer(\n",
    "            frames,\n",
    "            opts.near,\n",
    "            opts.far,\n",
    "            opts.depth_inference_steps,\n",
    "            opts.depth_guidance_scale,\n",
    "            window_size=opts.window_size,\n",
    "            overlap=opts.overlap,\n",
    "        ).to(opts.device)\n",
    "        \n",
    "        print(\"Converting frames to tensors...\")\n",
    "        frames_tensor = (\n",
    "            torch.from_numpy(frames).permute(0, 3, 1, 2).to(opts.device) * 2.0 - 1.0\n",
    "        )\n",
    "        \n",
    "        print(\"Generating camera poses...\")\n",
    "        pose_s, pose_t, K = self.get_poses(opts, depths, num_frames=opts.video_length)\n",
    "        \n",
    "        # Calculate scene radius\n",
    "        radius = (\n",
    "            depths[0, 0, depths.shape[-2] // 2, depths.shape[-1] // 2].cpu()\n",
    "            * opts.radius_scale\n",
    "        )\n",
    "        radius = min(radius, 5)\n",
    "        \n",
    "        return {\n",
    "            'frames_numpy': frames,\n",
    "            'frames_tensor': frames_tensor,\n",
    "            'depths': depths,\n",
    "            'pose_source': pose_s,\n",
    "            'pose_target': pose_t,\n",
    "            'intrinsics': K,\n",
    "            'radius': radius,\n",
    "            'trajectory_params': opts.target_pose if hasattr(opts, 'target_pose') else None\n",
    "        }\n",
    "        \n",
    "        \n",
    "    #################################################\n",
    "    # Circular trajectory\n",
    "    #################################################\n",
    "        \n",
    "    def generate_circular_trajectory(self, c2ws_anchor, circle_type, radius, num_frames, device, center_offset=(0,0,0)):\n",
    "        \"\"\"\n",
    "        Generate circular camera trajectory\n",
    "        \n",
    "        Args:\n",
    "            c2ws_anchor: Initial camera pose tensor\n",
    "            circle_type: 'horizontal', 'vertical_xz', 'vertical_yz', or 'tilted'\n",
    "            radius: Circle radius\n",
    "            num_frames: Number of frames\n",
    "            device: torch device\n",
    "            center_offset: (x,y,z) offset from origin\n",
    "        \"\"\"\n",
    "        angles = np.linspace(0, 2*np.pi, num_frames, endpoint=False)\n",
    "        c2ws_list = []\n",
    "        \n",
    "        for angle in angles:\n",
    "            c2w = copy.deepcopy(c2ws_anchor)\n",
    "            \n",
    "            if circle_type == 'horizontal':\n",
    "                # Circle in XY plane (horizontal orbit)\n",
    "                x = radius * np.cos(angle) + center_offset[0]\n",
    "                y = radius * np.sin(angle) + center_offset[1]\n",
    "                z = center_offset[2]\n",
    "                \n",
    "                # Set camera position\n",
    "                c2w[0, 0, 3] = x\n",
    "                c2w[0, 1, 3] = y  \n",
    "                c2w[0, 2, 3] = z\n",
    "                \n",
    "                # Point camera toward center (optional - creates look-at behavior)\n",
    "                # For now, just translate without rotation\n",
    "                \n",
    "            elif circle_type == 'vertical_xz':\n",
    "                # Circle in XZ plane (side view)\n",
    "                x = radius * np.cos(angle) + center_offset[0]\n",
    "                y = center_offset[1]\n",
    "                z = radius * np.sin(angle) + center_offset[2]\n",
    "                \n",
    "                c2w[0, 0, 3] = x\n",
    "                c2w[0, 1, 3] = y\n",
    "                c2w[0, 2, 3] = z\n",
    "                \n",
    "            elif circle_type == 'vertical_yz':\n",
    "                # Circle in YZ plane (front view)\n",
    "                x = center_offset[0]\n",
    "                y = radius * np.cos(angle) + center_offset[1]\n",
    "                z = radius * np.sin(angle) + center_offset[2]\n",
    "                \n",
    "                c2w[0, 0, 3] = x\n",
    "                c2w[0, 1, 3] = y\n",
    "                c2w[0, 2, 3] = z\n",
    "                \n",
    "            elif circle_type == 'tilted':\n",
    "                # 45° tilted circle\n",
    "                x = radius * np.cos(angle) + center_offset[0]\n",
    "                y = radius * np.sin(angle) * np.cos(np.pi/4) + center_offset[1]\n",
    "                z = radius * np.sin(angle) * np.sin(np.pi/4) + center_offset[2]\n",
    "                \n",
    "                c2w[0, 0, 3] = x\n",
    "                c2w[0, 1, 3] = y\n",
    "                c2w[0, 2, 3] = z\n",
    "            \n",
    "            c2ws_list.append(c2w)\n",
    "        \n",
    "        return torch.cat(c2ws_list, dim=0)\n",
    "    \n",
    "    \n",
    "    def get_poses_circular(self, opts, depths, num_frames, circle_type='horizontal', custom_radius=None):\n",
    "        \"\"\"\n",
    "        Generate circular camera poses instead of linear interpolation\n",
    "        \n",
    "        Args:\n",
    "            opts: Options object\n",
    "            depths: Depth maps\n",
    "            num_frames: Number of frames\n",
    "            circle_type: Type of circular motion\n",
    "            custom_radius: Override default radius calculation\n",
    "        \"\"\"\n",
    "        # Calculate radius (same as original)\n",
    "        if custom_radius is None:\n",
    "            radius = (\n",
    "                depths[0, 0, depths.shape[-2] // 2, depths.shape[-1] // 2].cpu()\n",
    "                * opts.radius_scale\n",
    "            )\n",
    "            radius = min(radius, 5)\n",
    "        else:\n",
    "            radius = custom_radius\n",
    "            \n",
    "        # Camera intrinsics (same as original)\n",
    "        cx = 512.0\n",
    "        cy = 288.0  \n",
    "        f = 500\n",
    "        K = (\n",
    "            torch.tensor([[f, 0.0, cx], [0.0, f, cy], [0.0, 0.0, 1.0]])\n",
    "            .repeat(num_frames, 1, 1)\n",
    "            .to(opts.device)\n",
    "        )\n",
    "        \n",
    "        # Initial camera pose (same as original)\n",
    "        c2w_init = (\n",
    "            torch.tensor([\n",
    "                [-1.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 1.0, 0.0, 0.0], \n",
    "                [0.0, 0.0, -1.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 1.0],\n",
    "            ])\n",
    "            .to(opts.device)\n",
    "            .unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "        # Generate circular trajectory\n",
    "        poses = self.generate_circular_trajectory(\n",
    "            c2w_init, circle_type, radius, num_frames, opts.device\n",
    "        )\n",
    "        \n",
    "        # Apply Z offset (same as original)\n",
    "        poses[:, 2, 3] = poses[:, 2, 3] + radius\n",
    "        \n",
    "        # Source and target poses\n",
    "        pose_s = poses[opts.anchor_idx : opts.anchor_idx + 1].repeat(num_frames, 1, 1)\n",
    "        pose_t = poses\n",
    "        \n",
    "        return pose_s, pose_t, K\n",
    "    \n",
    " \n",
    " # Utility function for easy use\n",
    "def create_circular_preset_params(preset_name):\n",
    "    \"\"\"Create parameters for common circular motion presets\"\"\"\n",
    "    presets = {\n",
    "        \"horizontal_circle\": {\n",
    "            \"circle_type\": \"horizontal\",\n",
    "            \"description\": \"Horizontal circular orbit around scene\"\n",
    "        },\n",
    "        \"vertical_orbit_xz\": {\n",
    "            \"circle_type\": \"vertical_xz\", \n",
    "            \"description\": \"Vertical orbit in XZ plane (side view)\"\n",
    "        },\n",
    "        \"vertical_orbit_yz\": {\n",
    "            \"circle_type\": \"vertical_yz\",\n",
    "            \"description\": \"Vertical orbit in YZ plane (front view)\" \n",
    "        },\n",
    "        \"tilted_orbit\": {\n",
    "            \"circle_type\": \"tilted\",\n",
    "            \"description\": \"45° tilted circular orbit\"\n",
    "        }\n",
    "    }\n",
    "    return presets.get(preset_name, presets[\"horizontal_circle\"])       \n",
    "        \n",
    "\n",
    "print(\"Classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Run Visualization\n",
    "# Initialize visualization TrajCrafter\n",
    "print(\"Initializing TrajCrafter for visualization...\")\n",
    "vis_crafter = TrajCrafterVisualization(opts_base)\n",
    "\n",
    "# Extract scene data\n",
    "print(\"Extracting scene data...\")\n",
    "scene_data = vis_crafter.extract_scene_data(opts_base)\n",
    "\n",
    "# Create warper for 3D point extraction\n",
    "print(\"Creating 3D point cloud from all frames...\")\n",
    "vis_warper = VisualizationWarper(device=opts_base.device)\n",
    "\n",
    "# Extract points from all frames\n",
    "all_points_3d = []\n",
    "all_colors_rgb = []\n",
    "\n",
    "num_frames = scene_data['frames_tensor'].shape[0]\n",
    "for i in tqdm(range(num_frames), desc=\"Processing frames\"):\n",
    "    frame_data = {\n",
    "        'frame': scene_data['frames_tensor'][i:i+1],\n",
    "        'depth': scene_data['depths'][i:i+1], \n",
    "        'pose_source': scene_data['pose_source'][i:i+1],\n",
    "        'intrinsics': scene_data['intrinsics'][i:i+1],\n",
    "    }\n",
    "    \n",
    "    points_3d_frame, colors_rgb_frame = vis_warper.extract_3d_points_with_colors(\n",
    "        frame_data['frame'],\n",
    "        frame_data['depth'], \n",
    "        frame_data['pose_source'],\n",
    "        frame_data['intrinsics'],\n",
    "        subsample_step=20  # Increased for performance with multiple frames\n",
    "    )\n",
    "    \n",
    "    if points_3d_frame.shape[0] > 0:  # Only add if we have valid points\n",
    "        all_points_3d.append(points_3d_frame)\n",
    "        all_colors_rgb.append(colors_rgb_frame)\n",
    "\n",
    "# Concatenate all points\n",
    "if all_points_3d:\n",
    "    points_3d = torch.cat(all_points_3d, dim=0)\n",
    "    colors_rgb = torch.cat(all_colors_rgb, dim=0)\n",
    "    print(f\"Generated {points_3d.shape[0]} 3D points from {len(all_points_3d)} frames\")\n",
    "else:\n",
    "    print(\"No valid 3D points extracted!\")\n",
    "    points_3d = None\n",
    "    colors_rgb = None\n",
    "\n",
    "print(f\"Camera trajectory: {scene_data['pose_target'].shape[0]} poses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Create Viser Server (run once)\n",
    "import viser\n",
    "\n",
    "# Check if server already exists and stop it\n",
    "try:\n",
    "    if 'viser_server' in globals() and viser_server is not None:\n",
    "        print(\"Stopping existing server...\")\n",
    "        viser_server.stop()\n",
    "        del viser_server\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create new server\n",
    "print(\"Creating new Viser server on port 8080...\")\n",
    "viser_server = viser.ViserServer(port=8080)\n",
    "print(\"Server started successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Animated Viser Content\n",
    "def setup_viser_scene(server, scene_data):\n",
    "    \"\"\"Setup static scene elements (trajectory and camera poses)\"\"\"\n",
    "\n",
    "    poses_np = scene_data['pose_target'].cpu().numpy()\n",
    "    positions = poses_np[:, :3, 3]\n",
    "    \n",
    "    # Add trajectory (static)\n",
    "    server.scene.add_spline_catmull_rom(\n",
    "        \"/trajectory\", \n",
    "        positions=positions, \n",
    "        color=(1.0, 0.0, 0.0), \n",
    "        line_width=3.0\n",
    "    )\n",
    "    \n",
    "    # Add all camera poses (static)\n",
    "    for i, pose in enumerate(poses_np[::2]):  # Every 2nd pose to reduce clutter\n",
    "        position = pose[:3, 3]\n",
    "        rotation_matrix = pose[:3, :3]\n",
    "        \n",
    "        print(position)\n",
    "        \n",
    "        # flip_z = np.array([[-1, 0, 0], [0, 1, 0], [0, 0, -1]])\n",
    "        # corrected_rotation = rotation_matrix @ flip_z\n",
    "        \n",
    "        corrected_rotation = rotation_matrix  # No correction\n",
    "        wxyz = viser.transforms.SO3.from_matrix(corrected_rotation).wxyz\n",
    "        \n",
    "        server.scene.add_camera_frustum(\n",
    "            f\"/camera_{i}\",\n",
    "            fov=60, aspect=16/9, scale=0.15,\n",
    "            position=position, wxyz=wxyz,\n",
    "            color=(0.8, 0.2, 0.2)\n",
    "        )\n",
    "    \n",
    "    # Add start/end markers\n",
    "    server.scene.add_icosphere(\"/start\", radius=0.1, position=positions[0], color=(0.0, 1.0, 0.0))\n",
    "    server.scene.add_icosphere(\"/end\", radius=0.1, position=positions[-1], color=(1.0, 0.0, 1.0))\n",
    "    server.scene.add_frame(\"/world\", axes_length=0.5, position=(0, 0, 0), wxyz=(1, 0, 0, 0))\n",
    "\n",
    "def animate_frame(server, scene_data, frame_idx, max_points=5000):\n",
    "    \"\"\"Update only the point cloud for given frame\"\"\"\n",
    "    # Clear previous frame\n",
    "    try:\n",
    "        server.scene.remove(\"/current_frame\")\n",
    "        server.scene.remove(\"/current_camera\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Extract points for this frame\n",
    "    frame_data = {\n",
    "        'frame': scene_data['frames_tensor'][frame_idx:frame_idx+1],\n",
    "        'depth': scene_data['depths'][frame_idx:frame_idx+1], \n",
    "        'pose_source': scene_data['pose_source'][frame_idx:frame_idx+1],\n",
    "        'intrinsics': scene_data['intrinsics'][frame_idx:frame_idx+1],\n",
    "    }\n",
    "    \n",
    "    points_3d, colors_rgb = vis_warper.extract_3d_points_with_colors(\n",
    "        frame_data['frame'], frame_data['depth'], \n",
    "        frame_data['pose_source'], frame_data['intrinsics'],\n",
    "        subsample_step=15\n",
    "    )\n",
    "    \n",
    "    if points_3d.shape[0] > 0:\n",
    "        points_np = points_3d.cpu().numpy()\n",
    "        colors_np = colors_rgb.cpu().numpy()\n",
    "        \n",
    "        # Limit points\n",
    "        if len(points_np) > max_points:\n",
    "            indices = np.random.choice(len(points_np), max_points, replace=False)\n",
    "            points_np = points_np[indices]\n",
    "            colors_np = colors_np[indices]\n",
    "        \n",
    "        if colors_np.min() < 0:\n",
    "            colors_np = (colors_np + 1) / 2\n",
    "            \n",
    "        # Update point cloud\n",
    "        server.scene.add_point_cloud(\n",
    "            \"/current_frame\", \n",
    "            points=points_np, \n",
    "            colors=colors_np, \n",
    "            point_size=0.03\n",
    "        )\n",
    "        \n",
    "        # Highlight current camera\n",
    "        pos = scene_data['pose_target'][frame_idx, :3, 3].cpu().numpy()\n",
    "        server.scene.add_icosphere(\n",
    "            \"/current_camera\", \n",
    "            radius=0.08, \n",
    "            position=pos, \n",
    "            color=(1.0, 1.0, 0.0)  # Yellow\n",
    "        )\n",
    "\n",
    "# Setup scene\n",
    "setup_viser_scene(viser_server, scene_data)\n",
    "\n",
    "# Create GUI controls for animation\n",
    "@viser_server.on_client_connect\n",
    "def _(client: viser.ClientHandle) -> None:\n",
    "    # Animation controls\n",
    "    play_button = client.gui.add_button(\"Play/Pause\")\n",
    "    frame_slider = client.gui.add_slider(\n",
    "        \"Frame\", \n",
    "        min=0, \n",
    "        max=scene_data['frames_tensor'].shape[0]-1, \n",
    "        step=1, \n",
    "        initial_value=0\n",
    "    )\n",
    "    speed_slider = client.gui.add_slider(\n",
    "        \"Speed\", \n",
    "        min=1, \n",
    "        max=10.0, \n",
    "        step=0.1, \n",
    "        initial_value=3.0\n",
    "    )\n",
    "    \n",
    "    # Animation state\n",
    "    is_playing = [False]\n",
    "    \n",
    "    @play_button.on_click\n",
    "    def _(_):\n",
    "        is_playing[0] = not is_playing[0]\n",
    "        \n",
    "    @frame_slider.on_update\n",
    "    def _(_):\n",
    "        animate_frame(viser_server, scene_data, frame_slider.value)\n",
    "    \n",
    "    # Animation loop\n",
    "    import threading\n",
    "    import time\n",
    "    \n",
    "    def animation_loop():\n",
    "        while True:\n",
    "            if is_playing[0]:\n",
    "                current_frame = frame_slider.value\n",
    "                next_frame = (current_frame + 1) % scene_data['frames_tensor'].shape[0]\n",
    "                frame_slider.value = next_frame\n",
    "                animate_frame(viser_server, scene_data, next_frame)\n",
    "            time.sleep(0.5 / speed_slider.value)\n",
    "    \n",
    "    # Start animation thread\n",
    "    animation_thread = threading.Thread(target=animation_loop, daemon=True)\n",
    "    animation_thread.start()\n",
    "\n",
    "# Show first frame\n",
    "animate_frame(viser_server, scene_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Viser GUI Controls\n",
    "##########################################\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import viser\n",
    "\n",
    "\n",
    "# Simple Point Size Control\n",
    "@viser_server.on_client_connect\n",
    "def _(client: viser.ClientHandle) -> None:\n",
    "    \n",
    "    update_camera_position()\n",
    "    \n",
    "    # Add simple point size slider\n",
    "    point_size_slider = client.gui.add_slider(\n",
    "        \"Point Size\",\n",
    "        min=0.005,\n",
    "        max=0.1,\n",
    "        step=0.005,\n",
    "        initial_value=0.015,\n",
    "    )\n",
    "    \n",
    "    # Update point size when slider changes\n",
    "    @point_size_slider.on_update\n",
    "    def _(_) -> None:\n",
    "        if points_3d is not None:\n",
    "            points_np = points_3d.cpu().numpy()\n",
    "            colors_np = colors_rgb.cpu().numpy()\n",
    "            if colors_np.min() < 0:\n",
    "                colors_np = (colors_np + 1) / 2\n",
    "            viser_server.scene.add_point_cloud(\n",
    "                \"/scene_points\",\n",
    "                points=points_np,\n",
    "                colors=colors_np,\n",
    "                point_size=point_size_slider.value\n",
    "            )\n",
    "\n",
    "# Set initial camera position\n",
    "initial_theta = 0\n",
    "initial_phi = 75\n",
    "initial_roll = -90\n",
    "initial_radius = 10\n",
    "\n",
    "# Add sliders for camera control (no global variables needed)\n",
    "theta_slider = viser_server.gui.add_slider(\n",
    "    \"Camera Theta (deg)\",\n",
    "    min=0, max=360, step=1, initial_value=initial_theta,\n",
    ")\n",
    "\n",
    "phi_slider = viser_server.gui.add_slider(\n",
    "    \"Camera Phi (deg)\", \n",
    "    min=-90, max=270, step=1, initial_value=initial_phi,\n",
    ")\n",
    "\n",
    "roll_slider = viser_server.gui.add_slider(\n",
    "    \"Camera Roll (deg)\",\n",
    "    min=-180, max=180, step=1, initial_value=initial_roll,\n",
    ")\n",
    "\n",
    "radius_slider = viser_server.gui.add_slider(\n",
    "    \"Camera Distance\",\n",
    "    min=1, max=20, step=0.1, initial_value=initial_radius,\n",
    ")\n",
    "\n",
    "def update_camera_position():\n",
    "    theta = math.radians(theta_slider.value)\n",
    "    phi = math.radians(phi_slider.value)\n",
    "    r = radius_slider.value\n",
    "    roll = math.radians(roll_slider.value)\n",
    "    \n",
    "    # Convert spherical to cartesian\n",
    "    x = r * math.cos(phi) * math.cos(theta)\n",
    "    y = r * math.cos(phi) * math.sin(theta) \n",
    "    z = r * math.sin(phi)\n",
    "    \n",
    "    position = np.array([x, y, z])\n",
    "    look_at = np.array([0, 0, 0])\n",
    "    \n",
    "    # Calculate camera's forward direction\n",
    "    forward = (look_at - position)\n",
    "    forward = forward / np.linalg.norm(forward)\n",
    "    \n",
    "    # Handle world up vector based on phi angle to prevent flipping\n",
    "    if abs(phi) < math.pi/2:  # -90° to +90°: normal \"above horizon\" view\n",
    "        world_up = np.array([0, 0, 1])\n",
    "    else:  # Beyond ±90°: \"below horizon\" or \"upside down\" view\n",
    "        world_up = np.array([0, 0, -1])  # Flip world up\n",
    "    \n",
    "    # Calculate right vector\n",
    "    right = np.cross(forward, world_up)\n",
    "    if np.linalg.norm(right) < 1e-6:  # Handle gimbal lock at poles\n",
    "        # Use a fallback right vector\n",
    "        right = np.array([1, 0, 0]) if abs(theta) < math.pi else np.array([-1, 0, 0])\n",
    "    else:\n",
    "        right = right / np.linalg.norm(right)\n",
    "    \n",
    "    # Calculate up vector\n",
    "    up_initial = np.cross(right, forward)\n",
    "    up_initial = up_initial / np.linalg.norm(up_initial)\n",
    "    \n",
    "    # Apply roll rotation around the forward axis\n",
    "    cos_roll = np.cos(roll)\n",
    "    sin_roll = np.sin(roll)\n",
    "    up = cos_roll * up_initial + sin_roll * right\n",
    "    \n",
    "    # Set camera using the correct API\n",
    "    for client in viser_server.get_clients().values():\n",
    "        client.camera.position = position\n",
    "        client.camera.look_at = look_at\n",
    "        client.camera.up_direction = up\n",
    "        \n",
    "\n",
    "@theta_slider.on_update\n",
    "def _(_):\n",
    "    update_camera_position()\n",
    "    \n",
    "@phi_slider.on_update \n",
    "def _(_):\n",
    "    update_camera_position()\n",
    "    \n",
    "@radius_slider.on_update\n",
    "def _(_):\n",
    "    update_camera_position()\n",
    "\n",
    "@roll_slider.on_update\n",
    "def _(_):\n",
    "    update_camera_position()\n",
    "\n",
    "# Apply initial camera position\n",
    "# update_camera_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: To test different trajectories (example)\n",
    "# Change your trajectory and re-run the update\n",
    "opts_test = copy.deepcopy(opts_base)\n",
    "opts_test.target_pose = [0, 90, 1, 0, 0]  # 180° rotation\n",
    "\n",
    "# Generate new scene data\n",
    "scene_data_test = vis_crafter.extract_scene_data(opts_test)\n",
    "\n",
    "# Update the same server with new content\n",
    "update_viser_content(viser_server, scene_data_test, points_3d, colors_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Camera trajectory visualization\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract scene data (same as your existing code)\n",
    "scene_data = vis_crafter.extract_scene_data(opts_base)\n",
    "\n",
    "# Generate CIRCULAR trajectory instead of linear\n",
    "def generate_circular_scene_data(crafter, opts, scene_data, circle_type='horizontal'):\n",
    "    \"\"\"Generate new scene data with circular motion\"\"\"\n",
    "    \n",
    "    # Reuse existing depths and frames\n",
    "    pose_s, pose_t, K = crafter.get_poses_circular(\n",
    "        opts, \n",
    "        scene_data['depths'], \n",
    "        num_frames=opts.video_length,\n",
    "        circle_type=circle_type\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'frames_numpy': scene_data['frames_numpy'],\n",
    "        'frames_tensor': scene_data['frames_tensor'],\n",
    "        'depths': scene_data['depths'], \n",
    "        'pose_source': pose_s,\n",
    "        'pose_target': pose_t,\n",
    "        'intrinsics': K,\n",
    "        'radius': scene_data['radius'],\n",
    "        'trajectory_params': f\"circular_{circle_type}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate different circular motions\n",
    "# horizontal_circle = generate_circular_scene_data(vis_crafter, opts_base, scene_data, 'horizontal')\n",
    "vertical_circle = generate_circular_scene_data(vis_crafter, opts_base, scene_data, 'vertical_xz')\n",
    "\n",
    "# Use in your existing Viser visualization\n",
    "# update_trajectory_visualization(viser_server, horizontal_circle)\n",
    "update_trajectory_visualization(viser_server, vertical_circle)\n",
    "\n",
    "print(\"Circular trajectories generated!\")\n",
    "print(\"Available types: horizontal, vertical_xz, vertical_yz, tilted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Camera trajectory visualization - Multiple Trajectories\n",
    "##########################################################################\n",
    "\n",
    "def generate_new_trajectory(vis_crafter, opts_base, target_pose_params, scene_data):\n",
    "    \"\"\"Generate new trajectory without recomputing point clouds\"\"\"\n",
    "    print(f\"Generating trajectory for pose: {target_pose_params}\")\n",
    "    \n",
    "    # Create new opts with different target pose\n",
    "    opts_new = copy.deepcopy(opts_base)\n",
    "    opts_new.target_pose = target_pose_params\n",
    "    \n",
    "    # Only regenerate poses, reuse existing depths\n",
    "    # pose_s, pose_t, K = vis_crafter.get_poses(opts_new, scene_data['depths'], num_frames=opts_new.video_length)\n",
    "    pose_s, pose_t, K = vis_crafter.get_poses_circular(\n",
    "        opts_new, \n",
    "        scene_data['depths'], \n",
    "        num_frames=opts_new.video_length,\n",
    "        circle_type='horizontal'  # or other types based on params\n",
    "    )\n",
    "    \n",
    "    # Create new scene data with same point clouds but new trajectory\n",
    "    new_scene_data = {\n",
    "        'frames_numpy': scene_data['frames_numpy'],\n",
    "        'frames_tensor': scene_data['frames_tensor'], \n",
    "        'depths': scene_data['depths'],\n",
    "        'pose_source': pose_s,\n",
    "        'pose_target': pose_t,\n",
    "        'intrinsics': K,\n",
    "        'radius': scene_data['radius'],\n",
    "        'trajectory_params': target_pose_params\n",
    "    }\n",
    "    \n",
    "    return new_scene_data\n",
    "\n",
    "def update_trajectory_visualization(server, new_scene_data):\n",
    "    \"\"\"Update only the trajectory visualization, keep point clouds\"\"\"\n",
    "    \n",
    "    # Clear existing trajectory elements\n",
    "    try:\n",
    "        server.scene.remove(\"/trajectory\")\n",
    "        for i in range(50):  # Clear up to 50 camera poses\n",
    "            try:\n",
    "                server.scene.remove(f\"/camera_{i}\")\n",
    "            except:\n",
    "                break\n",
    "        server.scene.remove(\"/start\")\n",
    "        server.scene.remove(\"/end\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Add new trajectory\n",
    "    poses_np = new_scene_data['pose_target'].cpu().numpy()\n",
    "    positions = poses_np[:, :3, 3]\n",
    "    \n",
    "    # Add trajectory spline\n",
    "    server.scene.add_spline_catmull_rom(\n",
    "        \"/trajectory\", \n",
    "        positions=positions, \n",
    "        color=(1.0, 0.0, 0.0), \n",
    "        line_width=3.0\n",
    "    )\n",
    "    \n",
    "    # Add camera poses (every 2nd to reduce clutter)\n",
    "    for i, pose in enumerate(poses_np[::2]):\n",
    "        position = pose[:3, 3]\n",
    "        rotation_matrix = pose[:3, :3]\n",
    "        \n",
    "        # flip_z = np.array([[-1, 0, 0], [0, 1, 0], [0, 0, -1]])\n",
    "        # corrected_rotation = rotation_matrix @ flip_z\n",
    "        \n",
    "        corrected_rotation = rotation_matrix  # No correction\n",
    "        wxyz = viser.transforms.SO3.from_matrix(corrected_rotation).wxyz\n",
    "        \n",
    "        server.scene.add_camera_frustum(\n",
    "            f\"/camera_{i}\",\n",
    "            fov=60, aspect=16/9, scale=0.15,\n",
    "            position=position, wxyz=wxyz,\n",
    "            color=(0.8, 0.2, 0.2)\n",
    "        )\n",
    "    \n",
    "    # Add new start/end markers\n",
    "    server.scene.add_icosphere(\"/start\", radius=0.1, position=positions[0], color=(0.0, 1.0, 0.0))\n",
    "    server.scene.add_icosphere(\"/end\", radius=0.1, position=positions[-1], color=(1.0, 0.0, 1.0))\n",
    "\n",
    "# Predefined trajectory presets\n",
    "TRAJECTORY_PRESETS = {\n",
    "    \"Original Right 90°\": [0, 90, 1, 0, 0],\n",
    "    \"Left 90°\": [0, -90, 1, 0, 0], \n",
    "    \"Full Circle\": [0, 360, 1, 0, 0],\n",
    "    \"Up and Right\": [45, 45, 0.5, 0, 1],\n",
    "    \"Pull Back\": [0, 0, 3, 0, 0],\n",
    "    \"Orbit Up\": [30, 180, 0, 0, 0],\n",
    "    \"Dolly Forward\": [0, 0, -2, 0, 0],\n",
    "    \"Rise and Turn\": [60, 120, 1, 0, 2],\n",
    "}\n",
    "\n",
    "# Create trajectory selection GUI\n",
    "@viser_server.on_client_connect  \n",
    "def _(client: viser.ClientHandle) -> None:\n",
    "    \n",
    "    # Trajectory selection dropdown\n",
    "    trajectory_dropdown = client.gui.add_dropdown(\n",
    "        \"Trajectory Preset\",\n",
    "        options=list(TRAJECTORY_PRESETS.keys()),\n",
    "        initial_value=\"Original Right 90°\"\n",
    "    )\n",
    "    \n",
    "    # Manual trajectory controls\n",
    "    with client.gui.add_folder(\"Custom Trajectory\"):\n",
    "        theta_input = client.gui.add_slider(\"Theta (pitch)\", min=-90, max=90, step=1, initial_value=0)\n",
    "        phi_input = client.gui.add_slider(\"Phi (yaw)\", min=-360, max=360, step=5, initial_value=90)\n",
    "        dr_input = client.gui.add_slider(\"Distance\", min=-3, max=3, step=0.1, initial_value=1.0)\n",
    "        dx_input = client.gui.add_slider(\"X offset\", min=-2, max=2, step=0.1, initial_value=0.0)\n",
    "        dy_input = client.gui.add_slider(\"Y offset\", min=-2, max=2, step=0.1, initial_value=0.0)\n",
    "        \n",
    "        generate_button = client.gui.add_button(\"Generate Custom Trajectory\")\n",
    "    \n",
    "    # Display current trajectory info\n",
    "    trajectory_info = client.gui.add_text(\"Trajectory Info\", initial_value=\"Current: [0, 90, 1, 0, 0]\")\n",
    "    \n",
    "    # Global reference to current scene data\n",
    "    current_scene_data = [scene_data]  # Use list for mutability\n",
    "    \n",
    "    @trajectory_dropdown.on_update\n",
    "    def _(_):\n",
    "        selected_preset = trajectory_dropdown.value\n",
    "        target_pose = TRAJECTORY_PRESETS[selected_preset]\n",
    "        \n",
    "        # Generate new trajectory\n",
    "        new_scene_data = generate_new_trajectory(vis_crafter, opts_base, target_pose, scene_data)\n",
    "        current_scene_data[0] = new_scene_data\n",
    "        \n",
    "        # Update visualization\n",
    "        update_trajectory_visualization(viser_server, new_scene_data)\n",
    "        \n",
    "        # Update info\n",
    "        trajectory_info.value = f\"Current: {target_pose}\"\n",
    "        \n",
    "        # Update manual controls to match preset\n",
    "        theta_input.value = target_pose[0]\n",
    "        phi_input.value = target_pose[1] \n",
    "        dr_input.value = target_pose[2]\n",
    "        dx_input.value = target_pose[3]\n",
    "        dy_input.value = target_pose[4]\n",
    "        \n",
    "        print(f\"Switched to trajectory: {selected_preset} -> {target_pose}\")\n",
    "    \n",
    "    @generate_button.on_click\n",
    "    def _(_):\n",
    "        custom_pose = [theta_input.value, phi_input.value, dr_input.value, dx_input.value, dy_input.value]\n",
    "        \n",
    "        # Generate new trajectory\n",
    "        new_scene_data = generate_new_trajectory(vis_crafter, opts_base, custom_pose, scene_data)\n",
    "        current_scene_data[0] = new_scene_data\n",
    "        \n",
    "        # Update visualization  \n",
    "        update_trajectory_visualization(viser_server, new_scene_data)\n",
    "        \n",
    "        # Update info\n",
    "        trajectory_info.value = f\"Current: {custom_pose}\"\n",
    "        \n",
    "        print(f\"Generated custom trajectory: {custom_pose}\")\n",
    "    \n",
    "    # Animation controls for current trajectory\n",
    "    with client.gui.add_folder(\"Animation\"):\n",
    "        play_button = client.gui.add_button(\"Play/Pause\")\n",
    "        frame_slider = client.gui.add_slider(\n",
    "            \"Frame\", \n",
    "            min=0, \n",
    "            max=scene_data['frames_tensor'].shape[0]-1, \n",
    "            step=1, \n",
    "            initial_value=0\n",
    "        )\n",
    "        speed_slider = client.gui.add_slider(\"Speed\", min=0.5, max=5.0, step=0.1, initial_value=1.0)\n",
    "    \n",
    "    # Animation state\n",
    "    is_playing = [False]\n",
    "    \n",
    "    @play_button.on_click\n",
    "    def _(_):\n",
    "        is_playing[0] = not is_playing[0]\n",
    "        \n",
    "    @frame_slider.on_update\n",
    "    def _(_):\n",
    "        animate_frame(viser_server, current_scene_data[0], frame_slider.value)\n",
    "    \n",
    "    # Animation loop\n",
    "    import threading\n",
    "    import time\n",
    "    \n",
    "    def animation_loop():\n",
    "        while True:\n",
    "            if is_playing[0]:\n",
    "                current_frame = frame_slider.value\n",
    "                next_frame = (current_frame + 1) % current_scene_data[0]['frames_tensor'].shape[0]\n",
    "                frame_slider.value = next_frame\n",
    "                animate_frame(viser_server, current_scene_data[0], next_frame)\n",
    "            time.sleep(1.0 / speed_slider.value)\n",
    "    \n",
    "    # Start animation thread\n",
    "    animation_thread = threading.Thread(target=animation_loop, daemon=True)\n",
    "    animation_thread.start()\n",
    "\n",
    "print(\"Trajectory visualization setup complete!\")\n",
    "print(\"Available presets:\", list(TRAJECTORY_PRESETS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and print trajectory numbers for a few presets\n",
    "target_poses = {\n",
    "    \"Right 90°\": [0, 90, 1, 0, 0],\n",
    "    \"Full Circle\": [0, 360, 1, 0, 0],\n",
    "    \"Pull Back\": [0, 0, 3, 0, 0]\n",
    "}\n",
    "\n",
    "new_data = generate_new_trajectory(\n",
    "    vis_crafter, opts_base,\n",
    "    target_poses[\"Right 90°\"],\n",
    "    scene_data\n",
    "    )\n",
    "\n",
    "positions = new_data['pose_target'].cpu().numpy()[:, :3, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using maplotlib, plot the 0th and 2rd axis\n",
    "# Using matplotlib, plot the 0th and 2nd axis of positions variable\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot X vs Z (0th vs 2nd axis)\n",
    "plt.plot(positions[:, 0], positions[:, 2], 'b-o', linewidth=2, markersize=4)\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Z Position') \n",
    "plt.title('Camera Trajectory: X vs Z (Top-down view)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "\n",
    "# Mark start and end points\n",
    "plt.plot(positions[0, 0], positions[0, 2], 'go', markersize=10, label='Start')\n",
    "plt.plot(positions[-1, 0], positions[-1, 2], 'ro', markersize=10, label='End')\n",
    "\n",
    "# Add frame numbers for reference\n",
    "for i in range(0, len(positions), max(1, len(positions)//8)):\n",
    "    plt.annotate(f'{i}', (positions[i, 0], positions[i, 2]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the trajectory values\n",
    "print(f\"Trajectory shape: {positions.shape}\")\n",
    "print(f\"X range: {positions[:, 0].min():.3f} to {positions[:, 0].max():.3f}\")\n",
    "print(f\"Z range: {positions[:, 2].min():.3f} to {positions[:, 2].max():.3f}\")\n",
    "print(f\"Start (X,Z): ({positions[0, 0]:.3f}, {positions[0, 2]:.3f})\")\n",
    "print(f\"End (X,Z): ({positions[-1, 0]:.3f}, {positions[-1, 2]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the coordinate system by examining a few poses\n",
    "poses = new_data['pose_target'].cpu().numpy()\n",
    "print(\"Shape:\", poses.shape)\n",
    "print(\"\\nFirst pose (Frame 0):\")\n",
    "print(poses[0])\n",
    "print(\"\\nPosition:\", poses[0][:3, 3])\n",
    "print(\"Rotation matrix:\")\n",
    "print(poses[0][:3, :3])\n",
    "\n",
    "# Check if it follows OpenCV or OpenGL convention\n",
    "print(\"\\nCoordinate system analysis:\")\n",
    "print(\"Z-axis (forward direction):\", poses[0][:3, 2])\n",
    "print(\"Y-axis (up direction):\", poses[0][:3, 1]) \n",
    "print(\"X-axis (right direction):\", poses[0][:3, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
