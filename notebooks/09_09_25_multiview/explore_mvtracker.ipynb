{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/azhuravl/work/mvtracker')\n",
    "\n",
    "# work/mvtracker/mvtracker/datasets/panoptic_studio_multiview_dataset.py\n",
    "\n",
    "from mvtracker.datasets.panoptic_studio_multiview_dataset import PanopticStudioMultiViewDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 videos from /home/azhuravl/nobackup/mvtracker_data/datasets/panoptic-multiview\n"
     ]
    }
   ],
   "source": [
    "# dataset = PanopticStudioMultiViewDataset(\n",
    "#     '/home/azhuravl/nobackup/mvtracker_data/panoptic_studio/datasets/panoptic-multiview',\n",
    "#     \"traj_per_sample\": 384, \"seed\": 72,\n",
    "#     \"max_videos\": 1, \"perform_sanity_checks\": False, \"views_to_return\": [1, 7, 14, 20],\n",
    "#     \"use_duster_depths\": False, \"clean_duster_depths\": False,\n",
    "# )\n",
    "\n",
    "dataset = PanopticStudioMultiViewDataset(\n",
    "    '/home/azhuravl/nobackup/mvtracker_data/datasets/panoptic-multiview',\n",
    "    traj_per_sample=384, seed=72,\n",
    "    max_videos=100, perform_sanity_checks=False, views_to_return=[1, 7],\n",
    "    use_duster_depths=False, clean_duster_depths=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 000000 took  9.114 sec. Getitem calls: 1\n",
      "video: torch.Size([2, 150, 3, 360, 640]), torch.float32\n",
      "segmentation: torch.Size([150, 1, 360, 640]), torch.float32\n",
      "videodepth: torch.Size([2, 150, 1, 360, 640]), torch.float32\n",
      "videodepthconf: <class 'NoneType'>\n",
      "feats: <class 'NoneType'>\n",
      "valid: torch.Size([150, 384]), torch.bool\n",
      "seq_name: <class 'str'>\n",
      "intrs: torch.Size([2, 150, 3, 3]), torch.float32\n",
      "query_points: <class 'NoneType'>\n",
      "query_points_3d: torch.Size([384, 4]), torch.float32\n",
      "trajectory: torch.Size([2, 150, 384, 3]), torch.float32\n",
      "visibility: torch.Size([2, 150, 384]), torch.uint8\n",
      "trajectory_3d: torch.Size([150, 384, 3]), torch.float32\n",
      "trajectory_category: <class 'NoneType'>\n",
      "extrs: torch.Size([2, 150, 3, 4]), torch.float32\n",
      "track_upscaling_factor: <class 'float'>\n",
      "novel_video: <class 'NoneType'>\n",
      "novel_intrs: <class 'NoneType'>\n",
      "novel_extrs: <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "\n",
    "# print each variable name and the size of the tensor, dtype\n",
    "for k, v in vars(data[0]).items():\n",
    "    if hasattr(v, 'shape'):\n",
    "        print(f\"{k}: {v.shape}, {v.dtype}\")\n",
    "    else:\n",
    "        print(f\"{k}: {type(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "def save_video_tensor_imageio(video_tensor, output_path, fps=15):\n",
    "    \"\"\"Save video tensor using imageio (more reliable)\"\"\"\n",
    "    video_np = video_tensor.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    \n",
    "    print(f\"Original video range: [{video_np.min():.3f}, {video_np.max():.3f}]\")\n",
    "    \n",
    "    # Normalize to [0, 255] and convert to uint8\n",
    "    if video_np.max() <= 1.0 and video_np.min() >= 0.0:\n",
    "        video_np = (video_np * 255).astype(np.uint8)\n",
    "    elif video_np.min() >= -1.0 and video_np.max() <= 1.0:\n",
    "        video_np = ((video_np + 1.0) / 2.0 * 255).astype(np.uint8)\n",
    "    else:\n",
    "        video_np = (video_np - video_np.min()) / (video_np.max() - video_np.min())\n",
    "        video_np = (video_np * 255).astype(np.uint8)\n",
    "    \n",
    "    print(f\"Converted range: [{video_np.min()}, {video_np.max()}]\")\n",
    "    print(f\"Shape: {video_np.shape}\")\n",
    "    \n",
    "    # Save with imageio\n",
    "    imageio.mimsave(output_path, video_np, fps=fps)\n",
    "    print(f\"Video saved to: {output_path}\")\n",
    "\n",
    "# Try with imageio\n",
    "# save_video_tensor_imageio(\n",
    "#     data[0].video[0],\n",
    "#     '/home/azhuravl/work/TrajectoryCrafter/notebooks/09_09_25_multiview/mvtracker_video.mp4',\n",
    "#     fps=15\n",
    "#     )\n",
    "\n",
    "save_video_tensor_imageio(\n",
    "    data[0].videodepth[0],\n",
    "    '/home/azhuravl/work/TrajectoryCrafter/notebooks/09_09_25_multiview/mvtracker_videodepth.mp4',\n",
    "    fps=15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"intrs\", data[0].intrs[0])\n",
    "print(\"extrs\", data[0].extrs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/azhuravl/work/mvtracker')\n",
    "\n",
    "# work/mvtracker/mvtracker/datasets/panoptic_studio_multiview_dataset.py\n",
    "\n",
    "from mvtracker.datasets.kubric_multiview_dataset import KubricMultiViewDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubric_dataset = KubricMultiViewDataset(\n",
    "    data_root = '/home/azhuravl/nobackup/mvtracker_data/datasets/kubric-multiview/test',\n",
    "    seq_len = 24,\n",
    "    traj_per_sample = 200,\n",
    "    seed = 72,\n",
    "    sample_vis_1st_frame = True,\n",
    "    tune_per_scene = False,\n",
    "    max_videos = 100,\n",
    "    use_duster_depths = False,\n",
    "    duster_views = None,\n",
    "    clean_duster_depths = False,\n",
    "    views_to_return = list(range(0, 10)),\n",
    "    # novel_views = [20, 21],\n",
    "    num_views = -1,\n",
    "    depth_noise_std = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video: torch.Size([10, 24, 3, 512, 512]), torch.float32\n",
      "segmentation: torch.Size([10, 24, 1, 512, 512]), torch.float32\n",
      "videodepth: torch.Size([10, 24, 1, 512, 512]), torch.float32\n",
      "videodepthconf: None\n",
      "feats: None\n",
      "valid: torch.Size([24, 200]), torch.float32\n",
      "seq_name: 1\n",
      "intrs: torch.Size([10, 24, 3, 3]), torch.float32\n",
      "query_points: None\n",
      "query_points_3d: torch.Size([200, 4]), torch.float32\n",
      "trajectory: torch.Size([10, 24, 200, 3]), torch.float32\n",
      "visibility: torch.Size([10, 24, 200]), torch.bool\n",
      "trajectory_3d: torch.Size([24, 200, 3]), torch.float32\n",
      "trajectory_category: None\n",
      "extrs: torch.Size([10, 24, 3, 4]), torch.float32\n",
      "track_upscaling_factor: 1.0\n",
      "novel_video: None\n",
      "novel_intrs: None\n",
      "novel_extrs: None\n"
     ]
    }
   ],
   "source": [
    "data = kubric_dataset[0]\n",
    "\n",
    "# print each variable name and the size of the tensor, dtype\n",
    "for k, v in vars(data[0]).items():\n",
    "    if hasattr(v, 'shape'):\n",
    "        print(f\"{k}: {v.shape}, {v.dtype}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Camera 0 and Camera 1 Relationship ===\n",
      "  Camera 2 is rotated 130.5° to the right of Camera 1\n",
      "  Camera 2 is looking 23.4° above Camera 1's view\n",
      "  Cameras are 20.89 units apart\n",
      "\n",
      "=== Camera 0 and Camera 2 Relationship ===\n",
      "  Camera 2 is rotated 113.3° to the left of Camera 1\n",
      "  Camera 2 is looking 38.9° below Camera 1's view\n",
      "  Cameras are 19.43 units apart\n",
      "\n",
      "=== Camera 0 and Camera 3 Relationship ===\n",
      "  Camera 2 is rotated 18.0° to the right of Camera 1\n",
      "  Camera 2 is looking 54.7° above Camera 1's view\n",
      "  Cameras are 15.62 units apart\n",
      "\n",
      "=== Camera 0 and Camera 4 Relationship ===\n",
      "  Camera 2 is rotated 177.6° to the left of Camera 1\n",
      "  Camera 2 is looking 14.4° below Camera 1's view\n",
      "  Cameras are 25.14 units apart\n",
      "\n",
      "=== Camera 0 and Camera 5 Relationship ===\n",
      "  Camera 2 is rotated 176.6° to the right of Camera 1\n",
      "  Camera 2 is looking 15.1° above Camera 1's view\n",
      "  Cameras are 24.19 units apart\n",
      "\n",
      "=== Camera 0 and Camera 6 Relationship ===\n",
      "  Camera 2 is rotated 34.9° to the left of Camera 1\n",
      "  Camera 2 is looking 68.1° below Camera 1's view\n",
      "  Cameras are 15.76 units apart\n",
      "\n",
      "=== Camera 0 and Camera 7 Relationship ===\n",
      "  Camera 2 is rotated 177.5° to the right of Camera 1\n",
      "  Camera 2 is looking 73.3° above Camera 1's view\n",
      "  Cameras are 23.68 units apart\n",
      "\n",
      "=== Camera 0 and Camera 8 Relationship ===\n",
      "  Camera 2 is rotated 16.5° to the left of Camera 1\n",
      "  Camera 2 is looking 9.8° below Camera 1's view\n",
      "  Cameras are 10.05 units apart\n",
      "\n",
      "=== Camera 0 and Camera 9 Relationship ===\n",
      "  Camera 2 is rotated 178.1° to the right of Camera 1\n",
      "  Camera 2 is looking 1.3° above Camera 1's view\n",
      "  Cameras are 19.67 units apart\n",
      "\n",
      "=== Camera 1 and Camera 2 Relationship ===\n",
      "  Camera 2 is rotated 133.5° to the right of Camera 1\n",
      "  Camera 2 is looking 32.5° above Camera 1's view\n",
      "  Cameras are 15.91 units apart\n",
      "\n",
      "=== Camera 1 and Camera 3 Relationship ===\n",
      "  Camera 2 is rotated 30.3° to the left of Camera 1\n",
      "  Camera 2 is looking 66.5° below Camera 1's view\n",
      "  Cameras are 15.11 units apart\n",
      "\n",
      "=== Camera 1 and Camera 4 Relationship ===\n",
      "  Camera 2 is rotated 21.9° to the right of Camera 1\n",
      "  Camera 2 is looking 66.2° above Camera 1's view\n",
      "  Cameras are 15.45 units apart\n",
      "\n",
      "=== Camera 1 and Camera 5 Relationship ===\n",
      "  Camera 2 is rotated 9.6° to the right of Camera 1\n",
      "  Camera 2 is looking 36.9° above Camera 1's view\n",
      "  Cameras are 10.60 units apart\n",
      "\n",
      "=== Camera 1 and Camera 6 Relationship ===\n",
      "  Camera 2 is rotated 175.6° to the right of Camera 1\n",
      "  Camera 2 is looking 18.3° above Camera 1's view\n",
      "  Cameras are 23.44 units apart\n",
      "\n",
      "=== Camera 1 and Camera 7 Relationship ===\n",
      "  Camera 2 is rotated 0.3° to the left of Camera 1\n",
      "  Camera 2 is looking 19.9° below Camera 1's view\n",
      "  Cameras are 13.71 units apart\n",
      "\n",
      "=== Camera 1 and Camera 8 Relationship ===\n",
      "  Camera 2 is rotated 149.7° to the left of Camera 1\n",
      "  Camera 2 is looking 17.0° below Camera 1's view\n",
      "  Cameras are 13.22 units apart\n",
      "\n",
      "=== Camera 1 and Camera 9 Relationship ===\n",
      "  Camera 2 is rotated 45.8° to the right of Camera 1\n",
      "  Camera 2 is looking 25.8° above Camera 1's view\n",
      "  Cameras are 9.08 units apart\n",
      "\n",
      "=== Camera 2 and Camera 3 Relationship ===\n",
      "  Camera 2 is rotated 176.6° to the right of Camera 1\n",
      "  Camera 2 is looking 15.0° above Camera 1's view\n",
      "  Cameras are 24.32 units apart\n",
      "\n",
      "=== Camera 2 and Camera 4 Relationship ===\n",
      "  Camera 2 is rotated 14.2° to the left of Camera 1\n",
      "  Camera 2 is looking 56.3° below Camera 1's view\n",
      "  Cameras are 12.49 units apart\n",
      "\n",
      "=== Camera 2 and Camera 5 Relationship ===\n",
      "  Camera 2 is rotated 78.5° to the left of Camera 1\n",
      "  Camera 2 is looking 77.3° below Camera 1's view\n",
      "  Cameras are 16.42 units apart\n",
      "\n",
      "=== Camera 2 and Camera 6 Relationship ===\n",
      "  Camera 2 is rotated 9.2° to the right of Camera 1\n",
      "  Camera 2 is looking 34.7° above Camera 1's view\n",
      "  Cameras are 10.79 units apart\n",
      "\n",
      "=== Camera 2 and Camera 7 Relationship ===\n",
      "  Camera 2 is rotated 179.5° to the left of Camera 1\n",
      "  Camera 2 is looking 34.6° below Camera 1's view\n",
      "  Cameras are 24.26 units apart\n",
      "\n",
      "=== Camera 2 and Camera 8 Relationship ===\n",
      "  Camera 2 is rotated 88.7° to the right of Camera 1\n",
      "  Camera 2 is looking 31.2° above Camera 1's view\n",
      "  Cameras are 12.90 units apart\n",
      "\n",
      "=== Camera 2 and Camera 9 Relationship ===\n",
      "  Camera 2 is rotated 71.3° to the left of Camera 1\n",
      "  Camera 2 is looking 32.5° below Camera 1's view\n",
      "  Cameras are 9.00 units apart\n",
      "\n",
      "=== Camera 3 and Camera 4 Relationship ===\n",
      "  Camera 2 is rotated 171.7° to the right of Camera 1\n",
      "  Camera 2 is looking 41.4° above Camera 1's view\n",
      "  Cameras are 22.90 units apart\n",
      "\n",
      "=== Camera 3 and Camera 5 Relationship ===\n",
      "  Camera 2 is rotated 146.1° to the right of Camera 1\n",
      "  Camera 2 is looking 68.3° above Camera 1's view\n",
      "  Cameras are 17.43 units apart\n",
      "\n",
      "=== Camera 3 and Camera 6 Relationship ===\n",
      "  Camera 2 is rotated 164.4° to the left of Camera 1\n",
      "  Camera 2 is looking 49.3° below Camera 1's view\n",
      "  Cameras are 25.64 units apart\n",
      "\n",
      "=== Camera 3 and Camera 7 Relationship ===\n",
      "  Camera 2 is rotated 0.9° to the right of Camera 1\n",
      "  Camera 2 is looking 50.0° above Camera 1's view\n",
      "  Cameras are 10.81 units apart\n",
      "\n",
      "=== Camera 3 and Camera 8 Relationship ===\n",
      "  Camera 2 is rotated 73.5° to the left of Camera 1\n",
      "  Camera 2 is looking 30.2° below Camera 1's view\n",
      "  Cameras are 16.23 units apart\n",
      "\n",
      "=== Camera 3 and Camera 9 Relationship ===\n",
      "  Camera 2 is rotated 125.9° to the right of Camera 1\n",
      "  Camera 2 is looking 28.6° above Camera 1's view\n",
      "  Cameras are 18.15 units apart\n",
      "\n",
      "=== Camera 4 and Camera 5 Relationship ===\n",
      "  Camera 2 is rotated 7.1° to the left of Camera 1\n",
      "  Camera 2 is looking 29.3° below Camera 1's view\n",
      "  Cameras are 7.78 units apart\n",
      "\n",
      "=== Camera 4 and Camera 6 Relationship ===\n",
      "  Camera 2 is rotated 104.1° to the right of Camera 1\n",
      "  Camera 2 is looking 76.6° above Camera 1's view\n",
      "  Cameras are 18.38 units apart\n",
      "\n",
      "=== Camera 4 and Camera 7 Relationship ===\n",
      "  Camera 2 is rotated 19.6° to the left of Camera 1\n",
      "  Camera 2 is looking 87.8° below Camera 1's view\n",
      "  Cameras are 17.55 units apart\n",
      "\n",
      "=== Camera 4 and Camera 8 Relationship ===\n",
      "  Camera 2 is rotated 150.3° to the right of Camera 1\n",
      "  Camera 2 is looking 16.7° above Camera 1's view\n",
      "  Cameras are 20.28 units apart\n",
      "\n",
      "=== Camera 4 and Camera 9 Relationship ===\n",
      "  Camera 2 is rotated 14.1° to the left of Camera 1\n",
      "  Camera 2 is looking 9.3° below Camera 1's view\n",
      "  Cameras are 7.63 units apart\n",
      "\n",
      "=== Camera 5 and Camera 6 Relationship ===\n",
      "  Camera 2 is rotated 161.1° to the right of Camera 1\n",
      "  Camera 2 is looking 54.6° above Camera 1's view\n",
      "  Cameras are 22.55 units apart\n",
      "\n",
      "=== Camera 5 and Camera 7 Relationship ===\n",
      "  Camera 2 is rotated 1.2° to the left of Camera 1\n",
      "  Camera 2 is looking 57.9° below Camera 1's view\n",
      "  Cameras are 10.48 units apart\n",
      "\n",
      "=== Camera 5 and Camera 8 Relationship ===\n",
      "  Camera 2 is rotated 176.9° to the right of Camera 1\n",
      "  Camera 2 is looking 1.9° above Camera 1's view\n",
      "  Cameras are 19.22 units apart\n",
      "\n",
      "=== Camera 5 and Camera 9 Relationship ===\n",
      "  Camera 2 is rotated 11.0° to the right of Camera 1\n",
      "  Camera 2 is looking 7.3° above Camera 1's view\n",
      "  Cameras are 7.73 units apart\n",
      "\n",
      "=== Camera 6 and Camera 7 Relationship ===\n",
      "  Camera 2 is rotated 180.0° to the right of Camera 1\n",
      "  Camera 2 is looking 1.2° above Camera 1's view\n",
      "  Cameras are 27.97 units apart\n",
      "\n",
      "=== Camera 6 and Camera 8 Relationship ===\n",
      "  Camera 2 is rotated 48.7° to the right of Camera 1\n",
      "  Camera 2 is looking 24.5° above Camera 1's view\n",
      "  Cameras are 15.40 units apart\n",
      "\n",
      "=== Camera 6 and Camera 9 Relationship ===\n",
      "  Camera 2 is rotated 113.8° to the left of Camera 1\n",
      "  Camera 2 is looking 31.6° below Camera 1's view\n",
      "  Cameras are 16.41 units apart\n",
      "\n",
      "=== Camera 7 and Camera 8 Relationship ===\n",
      "  Camera 2 is rotated 130.1° to the left of Camera 1\n",
      "  Camera 2 is looking 24.9° below Camera 1's view\n",
      "  Cameras are 21.51 units apart\n",
      "\n",
      "=== Camera 7 and Camera 9 Relationship ===\n",
      "  Camera 2 is rotated 67.5° to the right of Camera 1\n",
      "  Camera 2 is looking 31.9° above Camera 1's view\n",
      "  Cameras are 15.70 units apart\n",
      "\n",
      "=== Camera 8 and Camera 9 Relationship ===\n",
      "  Camera 2 is rotated 166.0° to the left of Camera 1\n",
      "  Camera 2 is looking 9.3° below Camera 1's view\n",
      "  Cameras are 13.20 units apart\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def extrinsics_to_pose(extrs):\n",
    "    \"\"\"Convert [3,4] extrinsics [R|t] to 4x4 pose matrix\"\"\"\n",
    "    pose = torch.zeros(4, 4)\n",
    "    pose[:3, :] = extrs\n",
    "    pose[3, 3] = 1.0\n",
    "    return pose\n",
    "\n",
    "def rotation_matrix_to_euler(R):\n",
    "    \"\"\"Convert 3x3 rotation matrix to Euler angles (roll, pitch, yaw) in degrees\"\"\"\n",
    "    # Using XYZ convention (roll, pitch, yaw)\n",
    "    sy = torch.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "    \n",
    "    singular = sy < 1e-6\n",
    "    \n",
    "    if not singular:\n",
    "        x = torch.atan2(R[2, 1], R[2, 2])  # roll\n",
    "        y = torch.atan2(-R[2, 0], sy)      # pitch  \n",
    "        z = torch.atan2(R[1, 0], R[0, 0])  # yaw\n",
    "    else:\n",
    "        x = torch.atan2(-R[1, 2], R[1, 1])\n",
    "        y = torch.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "    \n",
    "    # Convert to degrees\n",
    "    return torch.rad2deg(torch.stack([x, y, z]))\n",
    "\n",
    "def calculate_relative_transform(extrs_1, extrs_2):\n",
    "    \"\"\"Calculate relative transformation from camera 1 to camera 2\"\"\"\n",
    "    # Convert to 4x4 poses\n",
    "    pose_1 = extrinsics_to_pose(extrs_1)\n",
    "    pose_2 = extrinsics_to_pose(extrs_2)\n",
    "    \n",
    "    # Calculate relative transformation: T_rel = T_2 * T_1^(-1)\n",
    "    pose_1_inv = torch.inverse(pose_1)\n",
    "    relative_pose = pose_2 @ pose_1_inv\n",
    "    \n",
    "    # Extract rotation and translation\n",
    "    R_rel = relative_pose[:3, :3]\n",
    "    t_rel = relative_pose[:3, 3]\n",
    "    \n",
    "    return R_rel, t_rel\n",
    "\n",
    "def describe_camera_relationship(extrs_1, extrs_2):\n",
    "    \"\"\"Generate human-readable description of camera relationship\"\"\"\n",
    "    R_rel, t_rel = calculate_relative_transform(extrs_1, extrs_2)\n",
    "    \n",
    "    # Convert rotation to Euler angles\n",
    "    euler_angles = rotation_matrix_to_euler(R_rel)\n",
    "    roll, pitch, yaw = euler_angles\n",
    "    \n",
    "    # Translation distance\n",
    "    translation_distance = torch.norm(t_rel).item()\n",
    "    \n",
    "    # Translation components\n",
    "    x_offset = t_rel[0].item()\n",
    "    y_offset = t_rel[1].item() \n",
    "    z_offset = t_rel[2].item()\n",
    "    \n",
    "    # print(\"=== Camera Relationship Analysis ===\")\n",
    "    # print(f\"Relative Translation:\")\n",
    "    # print(f\"  Distance: {translation_distance:.3f} units\")\n",
    "    # print(f\"  X offset: {x_offset:.3f} units ({'right' if x_offset > 0 else 'left'})\")\n",
    "    # print(f\"  Y offset: {y_offset:.3f} units ({'up' if y_offset > 0 else 'down'})\")  \n",
    "    # print(f\"  Z offset: {z_offset:.3f} units ({'forward' if z_offset > 0 else 'backward'})\")\n",
    "    \n",
    "    # print(f\"\\nRelative Rotation:\")\n",
    "    # print(f\"  Roll:  {roll:.2f}° ({'clockwise' if roll > 0 else 'counter-clockwise'})\")\n",
    "    # print(f\"  Pitch: {pitch:.2f}° ({'up' if pitch > 0 else 'down'})\")\n",
    "    # print(f\"  Yaw:   {yaw:.2f}° ({'right' if yaw > 0 else 'left'})\")\n",
    "    \n",
    "    # Simple interpretation\n",
    "    # print(f\"\\nSimple Description:\")\n",
    "    # if abs(yaw) > 45:\n",
    "    direction = \"right\" if yaw > 0 else \"left\"\n",
    "    print(f\"  Camera 2 is rotated {abs(yaw):.1f}° to the {direction} of Camera 1\")\n",
    "    \n",
    "    # if abs(pitch) > 15:\n",
    "    direction = \"above\" if pitch > 0 else \"below\"  \n",
    "    print(f\"  Camera 2 is looking {abs(pitch):.1f}° {direction} Camera 1's view\")\n",
    "    \n",
    "    # if translation_distance > 0.1:\n",
    "    print(f\"  Cameras are {translation_distance:.2f} units apart\")\n",
    "    \n",
    "    return R_rel, t_rel, euler_angles\n",
    "\n",
    "# Calculate and display the relationship\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(i + 1, 10):\n",
    "        if i == j:\n",
    "            continue\n",
    "        extrs_1 = data[0].extrs[i][0]\n",
    "        extrs_2 = data[0].extrs[j][0]\n",
    "        print(f\"\\n=== Camera {i} and Camera {j} Relationship ===\")\n",
    "        R_rel, t_rel, euler_angles = describe_camera_relationship(extrs_1, extrs_2)\n",
    "    # Get the two extrinsic matrices\n",
    "    # extrs_1 = data[0].extrs[0][0]  # [3, 4] - camera 1\n",
    "    # extrs_2 = data[0].extrs[i][0]  # [3, 4] - camera 2\n",
    "    \n",
    "    # print(f\"\\n=== Camera 0 and Camera {i} Relationship ===\")\n",
    "\n",
    "    # R_rel, t_rel, euler_angles = describe_camera_relationship(extrs_1, extrs_2)\n",
    "\n",
    "# Also show the raw matrices for reference\n",
    "# print(f\"\\n=== Raw Data ===\")\n",
    "# print(f\"Camera 1 extrinsics:\\n{extrs_1}\")\n",
    "# print(f\"Camera 2 extrinsics:\\n{extrs_2}\")\n",
    "# print(f\"Relative rotation matrix:\\n{R_rel}\")\n",
    "# print(f\"Relative translation vector: {t_rel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
