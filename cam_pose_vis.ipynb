{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/CT/video_4d_recon/nobackup/conda_envs/trajcrafter/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/CT/video_4d_recon/nobackup/conda_envs/trajcrafter/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n",
      "Working directory: /CT/video_4d_recon/work/TrajectoryCrafter\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Path Setup\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add TrajectoryCrafter to Python path\n",
    "trajcrafter_path = \"/home/azhuravl/work/TrajectoryCrafter\"\n",
    "sys.path.insert(0, trajcrafter_path)\n",
    "\n",
    "# Change working directory to TrajectoryCrafter\n",
    "os.chdir(trajcrafter_path)\n",
    "\n",
    "# Now import TrajectoryCrafter modules\n",
    "from demo import TrajCrafter\n",
    "from models.utils import Warper, read_video_frames\n",
    "from models.infer import DepthCrafterDemo\n",
    "import inference_orbits\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: ./test/videos/0-NNvgaTcVzAG0-r.mp4\n",
      "Target pose: [0, 90, 1.0, 0, 0]\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Argument Setup\n",
    "# Create opts manually for notebook use\n",
    "parser = inference_orbits.get_parser()\n",
    "opts_base = parser.parse_args([\n",
    "    '--video_path', './test/videos/0-NNvgaTcVzAG0-r.mp4',  # Change this path\n",
    "    '--radius', '1.0',\n",
    "    '--device', 'cuda:0'\n",
    "])\n",
    "\n",
    "# Set common parameters\n",
    "opts_base.weight_dtype = torch.bfloat16\n",
    "opts_base.camera = \"target\"\n",
    "opts_base.mode = \"gradual\"\n",
    "opts_base.mask = True\n",
    "opts_base.target_pose = [0, 90, opts_base.radius, 0, 0]  # right_90 example\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "video_basename = os.path.splitext(os.path.basename(opts_base.video_path))[0]\n",
    "opts_base.exp_name = f\"{video_basename}_{timestamp}_vis\"\n",
    "\n",
    "print(f\"Video: {opts_base.video_path}\")\n",
    "print(f\"Target pose: {opts_base.target_pose}\")\n",
    "print(f\"Device: {opts_base.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Visualization Classes\n",
    "class VisualizationWarper(Warper):\n",
    "    \"\"\"Extended Warper class for 3D visualization\"\"\"\n",
    "    \n",
    "    def extract_3d_points_with_colors(\n",
    "        self,\n",
    "        frame1: torch.Tensor,\n",
    "        depth1: torch.Tensor,\n",
    "        transformation1: torch.Tensor,\n",
    "        intrinsic1: torch.Tensor,\n",
    "        subsample_step: int = 10\n",
    "    ):\n",
    "        \"\"\"Extract 3D world points and their corresponding colors for visualization\"\"\"\n",
    "        b, c, h, w = frame1.shape\n",
    "        \n",
    "        # Move tensors to device\n",
    "        frame1 = frame1.to(self.device).to(self.dtype)\n",
    "        depth1 = depth1.to(self.device).to(self.dtype)\n",
    "        transformation1 = transformation1.to(self.device).to(self.dtype)\n",
    "        intrinsic1 = intrinsic1.to(self.device).to(self.dtype)\n",
    "        \n",
    "        # Create subsampled pixel coordinates for performance\n",
    "        x_coords = torch.arange(0, w, subsample_step, dtype=torch.float32)\n",
    "        y_coords = torch.arange(0, h, subsample_step, dtype=torch.float32)\n",
    "        x2d, y2d = torch.meshgrid(x_coords, y_coords, indexing='xy')\n",
    "        x2d = x2d.to(depth1.device)\n",
    "        y2d = y2d.to(depth1.device)\n",
    "        ones_2d = torch.ones_like(x2d)\n",
    "        \n",
    "        # Stack into homogeneous coordinates\n",
    "        pos_vectors_homo = torch.stack([x2d, y2d, ones_2d], dim=2)[None, :, :, :, None]\n",
    "        \n",
    "        # Subsample depth and colors\n",
    "        depth_sub = depth1[:, 0, ::subsample_step, ::subsample_step]\n",
    "        colors_sub = frame1[:, :, ::subsample_step, ::subsample_step]\n",
    "        \n",
    "        # Unproject to 3D camera coordinates\n",
    "        intrinsic1_inv = torch.linalg.inv(intrinsic1)\n",
    "        intrinsic1_inv_4d = intrinsic1_inv[:, None, None]\n",
    "        depth_4d = depth_sub[:, :, :, None, None]\n",
    "        \n",
    "        unnormalized_pos = torch.matmul(intrinsic1_inv_4d, pos_vectors_homo)\n",
    "        camera_points = depth_4d * unnormalized_pos\n",
    "        \n",
    "        # Transform to world coordinates\n",
    "        ones_4d = torch.ones(b, camera_points.shape[1], camera_points.shape[2], 1, 1).to(depth1)\n",
    "        world_points_homo = torch.cat([camera_points, ones_4d], dim=3)\n",
    "        trans_4d = transformation1[:, None, None]\n",
    "        world_points_homo = torch.matmul(trans_4d, world_points_homo)\n",
    "        world_points = world_points_homo[:, :, :, :3, 0]  # (b, h_sub, w_sub, 3)\n",
    "        \n",
    "        # Prepare colors\n",
    "        colors = colors_sub.permute(0, 2, 3, 1)  # (b, h_sub, w_sub, 3)\n",
    "        \n",
    "        # Filter valid points (positive depth)\n",
    "        valid_mask = depth_sub > 0  # (b, h_sub, w_sub)\n",
    "        \n",
    "        # Flatten and filter\n",
    "        points_3d = world_points[valid_mask]  # (N, 3)\n",
    "        colors_rgb = colors[valid_mask]       # (N, 3)\n",
    "        \n",
    "        return points_3d, colors_rgb\n",
    "\n",
    "\n",
    "class TrajCrafterVisualization(TrajCrafter):\n",
    "    \"\"\"Lightweight TrajCrafter subclass for camera trajectory visualization\"\"\"\n",
    "    \n",
    "    def __init__(self, opts):\n",
    "        # Only initialize what we need for pose generation and depth estimation\n",
    "        self.device = opts.device\n",
    "        self.depth_estimater = DepthCrafterDemo(\n",
    "            unet_path=opts.unet_path,\n",
    "            pre_train_path=opts.pre_train_path,\n",
    "            cpu_offload=opts.cpu_offload,\n",
    "            device=opts.device,\n",
    "        )\n",
    "        print(\"TrajCrafterVisualization initialized (diffusion pipeline skipped)\")\n",
    "    \n",
    "    def extract_scene_data(self, opts):\n",
    "        \"\"\"Extract all data needed for 3D visualization\"\"\"\n",
    "        print(\"Reading video frames...\")\n",
    "        frames = read_video_frames(\n",
    "            opts.video_path, opts.video_length, opts.stride, opts.max_res\n",
    "        )\n",
    "        \n",
    "        print(\"Estimating depth...\")\n",
    "        depths = self.depth_estimater.infer(\n",
    "            frames,\n",
    "            opts.near,\n",
    "            opts.far,\n",
    "            opts.depth_inference_steps,\n",
    "            opts.depth_guidance_scale,\n",
    "            window_size=opts.window_size,\n",
    "            overlap=opts.overlap,\n",
    "        ).to(opts.device)\n",
    "        \n",
    "        print(\"Converting frames to tensors...\")\n",
    "        frames_tensor = (\n",
    "            torch.from_numpy(frames).permute(0, 3, 1, 2).to(opts.device) * 2.0 - 1.0\n",
    "        )\n",
    "        \n",
    "        print(\"Generating camera poses...\")\n",
    "        pose_s, pose_t, K = self.get_poses(opts, depths, num_frames=opts.video_length)\n",
    "        \n",
    "        # Calculate scene radius\n",
    "        radius = (\n",
    "            depths[0, 0, depths.shape[-2] // 2, depths.shape[-1] // 2].cpu()\n",
    "            * opts.radius_scale\n",
    "        )\n",
    "        radius = min(radius, 5)\n",
    "        \n",
    "        return {\n",
    "            'frames_numpy': frames,\n",
    "            'frames_tensor': frames_tensor,\n",
    "            'depths': depths,\n",
    "            'pose_source': pose_s,\n",
    "            'pose_target': pose_t,\n",
    "            'intrinsics': K,\n",
    "            'radius': radius,\n",
    "            'trajectory_params': opts.target_pose if hasattr(opts, 'target_pose') else None\n",
    "        }\n",
    "        \n",
    "        \n",
    "    #################################################\n",
    "    # Circular trajectory\n",
    "    #################################################\n",
    "        \n",
    "    def generate_circular_trajectory(self, c2ws_anchor, circle_type, radius, num_frames, device, center_offset=(0,0,0)):\n",
    "        \"\"\"\n",
    "        Generate circular camera trajectory\n",
    "        \n",
    "        Args:\n",
    "            c2ws_anchor: Initial camera pose tensor\n",
    "            circle_type: 'horizontal', 'vertical_xz', 'vertical_yz', or 'tilted'\n",
    "            radius: Circle radius\n",
    "            num_frames: Number of frames\n",
    "            device: torch device\n",
    "            center_offset: (x,y,z) offset from origin\n",
    "        \"\"\"\n",
    "        angles = np.linspace(0, 2*np.pi, num_frames, endpoint=False)\n",
    "        c2ws_list = []\n",
    "        \n",
    "        for angle in angles:\n",
    "            c2w = copy.deepcopy(c2ws_anchor)\n",
    "            \n",
    "            if circle_type == 'horizontal':\n",
    "                # Circle in XY plane (horizontal orbit)\n",
    "                x = radius * np.cos(angle) + center_offset[0]\n",
    "                y = radius * np.sin(angle) + center_offset[1]\n",
    "                z = center_offset[2]\n",
    "                \n",
    "                # Set camera position\n",
    "                c2w[0, 0, 3] = x\n",
    "                c2w[0, 1, 3] = y  \n",
    "                c2w[0, 2, 3] = z\n",
    "                \n",
    "                # Point camera toward center (optional - creates look-at behavior)\n",
    "                # For now, just translate without rotation\n",
    "                \n",
    "            elif circle_type == 'vertical_xz':\n",
    "                # Circle in XZ plane (side view)\n",
    "                x = radius * np.cos(angle) + center_offset[0]\n",
    "                y = center_offset[1]\n",
    "                z = radius * np.sin(angle) + center_offset[2]\n",
    "                \n",
    "                c2w[0, 0, 3] = x\n",
    "                c2w[0, 1, 3] = y\n",
    "                c2w[0, 2, 3] = z\n",
    "                \n",
    "            elif circle_type == 'vertical_yz':\n",
    "                # Circle in YZ plane (front view)\n",
    "                x = center_offset[0]\n",
    "                y = radius * np.cos(angle) + center_offset[1]\n",
    "                z = radius * np.sin(angle) + center_offset[2]\n",
    "                \n",
    "                c2w[0, 0, 3] = x\n",
    "                c2w[0, 1, 3] = y\n",
    "                c2w[0, 2, 3] = z\n",
    "                \n",
    "            elif circle_type == 'tilted':\n",
    "                # 45° tilted circle\n",
    "                x = radius * np.cos(angle) + center_offset[0]\n",
    "                y = radius * np.sin(angle) * np.cos(np.pi/4) + center_offset[1]\n",
    "                z = radius * np.sin(angle) * np.sin(np.pi/4) + center_offset[2]\n",
    "                \n",
    "                c2w[0, 0, 3] = x\n",
    "                c2w[0, 1, 3] = y\n",
    "                c2w[0, 2, 3] = z\n",
    "            \n",
    "            c2ws_list.append(c2w)\n",
    "        \n",
    "        return torch.cat(c2ws_list, dim=0)\n",
    "    \n",
    "    \n",
    "    def get_poses_circular(self, opts, depths, num_frames, circle_type='horizontal', custom_radius=None):\n",
    "        \"\"\"\n",
    "        Generate circular camera poses instead of linear interpolation\n",
    "        \n",
    "        Args:\n",
    "            opts: Options object\n",
    "            depths: Depth maps\n",
    "            num_frames: Number of frames\n",
    "            circle_type: Type of circular motion\n",
    "            custom_radius: Override default radius calculation\n",
    "        \"\"\"\n",
    "        # Calculate radius (same as original)\n",
    "        if custom_radius is None:\n",
    "            radius = (\n",
    "                depths[0, 0, depths.shape[-2] // 2, depths.shape[-1] // 2].cpu()\n",
    "                * opts.radius_scale\n",
    "            )\n",
    "            radius = min(radius, 5)\n",
    "        else:\n",
    "            radius = custom_radius\n",
    "            \n",
    "        # Camera intrinsics (same as original)\n",
    "        cx = 512.0\n",
    "        cy = 288.0  \n",
    "        f = 500\n",
    "        K = (\n",
    "            torch.tensor([[f, 0.0, cx], [0.0, f, cy], [0.0, 0.0, 1.0]])\n",
    "            .repeat(num_frames, 1, 1)\n",
    "            .to(opts.device)\n",
    "        )\n",
    "        \n",
    "        # Initial camera pose (same as original)\n",
    "        c2w_init = (\n",
    "            torch.tensor([\n",
    "                [-1.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 1.0, 0.0, 0.0], \n",
    "                [0.0, 0.0, -1.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 1.0],\n",
    "            ])\n",
    "            .to(opts.device)\n",
    "            .unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "        # Generate circular trajectory\n",
    "        poses = self.generate_circular_trajectory(\n",
    "            c2w_init, circle_type, radius, num_frames, opts.device\n",
    "        )\n",
    "        \n",
    "        # Apply Z offset (same as original)\n",
    "        poses[:, 2, 3] = poses[:, 2, 3] + radius\n",
    "        \n",
    "        # Source and target poses\n",
    "        pose_s = poses[opts.anchor_idx : opts.anchor_idx + 1].repeat(num_frames, 1, 1)\n",
    "        pose_t = poses\n",
    "        \n",
    "        return pose_s, pose_t, K\n",
    "    \n",
    " \n",
    " # Utility function for easy use\n",
    "def create_circular_preset_params(preset_name):\n",
    "    \"\"\"Create parameters for common circular motion presets\"\"\"\n",
    "    presets = {\n",
    "        \"horizontal_circle\": {\n",
    "            \"circle_type\": \"horizontal\",\n",
    "            \"description\": \"Horizontal circular orbit around scene\"\n",
    "        },\n",
    "        \"vertical_orbit_xz\": {\n",
    "            \"circle_type\": \"vertical_xz\", \n",
    "            \"description\": \"Vertical orbit in XZ plane (side view)\"\n",
    "        },\n",
    "        \"vertical_orbit_yz\": {\n",
    "            \"circle_type\": \"vertical_yz\",\n",
    "            \"description\": \"Vertical orbit in YZ plane (front view)\" \n",
    "        },\n",
    "        \"tilted_orbit\": {\n",
    "            \"circle_type\": \"tilted\",\n",
    "            \"description\": \"45° tilted circular orbit\"\n",
    "        }\n",
    "    }\n",
    "    return presets.get(preset_name, presets[\"horizontal_circle\"])       \n",
    "        \n",
    "\n",
    "print(\"Classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TrajCrafter for visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected types for unet: ['UNetSpatioTemporalConditionModel'], got DiffusersUNetSpatioTemporalConditionModelDepthCrafter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2557acbf11d14d609da1b3aa04addbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrajCrafterVisualization initialized (diffusion pipeline skipped)\n",
      "Extracting scene data...\n",
      "Reading video frames...\n",
      "==> processing video:  ./test/videos/0-NNvgaTcVzAG0-r.mp4\n",
      "==> original video shape:  (146, 720, 1280, 3)\n",
      "==> downsampled shape: (146, 576, 1024, 3), with stride: 1\n",
      "==> final processing shape: (49, 576, 1024, 3)\n",
      "Estimating depth...\n",
      "Elapsed time for encoding video: 9515.4501953125 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190401d0569441e081318eb5385b3dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for denoising video: 20985.404296875 ms\n",
      "Elapsed time for decoding video: 18729.736328125 ms\n",
      "Converting frames to tensors...\n",
      "Generating camera poses...\n",
      "Creating 3D point cloud from all frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 497.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 73892 3D points from 49 frames\n",
      "Camera trajectory: 49 poses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Run Visualization\n",
    "# Initialize visualization TrajCrafter\n",
    "print(\"Initializing TrajCrafter for visualization...\")\n",
    "vis_crafter = TrajCrafterVisualization(opts_base)\n",
    "\n",
    "# Extract scene data\n",
    "print(\"Extracting scene data...\")\n",
    "scene_data = vis_crafter.extract_scene_data(opts_base)\n",
    "\n",
    "# Create warper for 3D point extraction\n",
    "print(\"Creating 3D point cloud from all frames...\")\n",
    "vis_warper = VisualizationWarper(device=opts_base.device)\n",
    "\n",
    "# Extract points from all frames\n",
    "all_points_3d = []\n",
    "all_colors_rgb = []\n",
    "\n",
    "num_frames = scene_data['frames_tensor'].shape[0]\n",
    "for i in tqdm(range(num_frames), desc=\"Processing frames\"):\n",
    "    frame_data = {\n",
    "        'frame': scene_data['frames_tensor'][i:i+1],\n",
    "        'depth': scene_data['depths'][i:i+1], \n",
    "        'pose_source': scene_data['pose_source'][i:i+1],\n",
    "        'intrinsics': scene_data['intrinsics'][i:i+1],\n",
    "    }\n",
    "    \n",
    "    points_3d_frame, colors_rgb_frame = vis_warper.extract_3d_points_with_colors(\n",
    "        frame_data['frame'],\n",
    "        frame_data['depth'], \n",
    "        frame_data['pose_source'],\n",
    "        frame_data['intrinsics'],\n",
    "        subsample_step=20  # Increased for performance with multiple frames\n",
    "    )\n",
    "    \n",
    "    if points_3d_frame.shape[0] > 0:  # Only add if we have valid points\n",
    "        all_points_3d.append(points_3d_frame)\n",
    "        all_colors_rgb.append(colors_rgb_frame)\n",
    "\n",
    "# Concatenate all points\n",
    "if all_points_3d:\n",
    "    points_3d = torch.cat(all_points_3d, dim=0)\n",
    "    colors_rgb = torch.cat(all_colors_rgb, dim=0)\n",
    "    print(f\"Generated {points_3d.shape[0]} 3D points from {len(all_points_3d)} frames\")\n",
    "else:\n",
    "    print(\"No valid 3D points extracted!\")\n",
    "    points_3d = None\n",
    "    colors_rgb = None\n",
    "\n",
    "print(f\"Camera trajectory: {scene_data['pose_target'].shape[0]} poses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping existing server...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection closed <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> total<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection closed \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m total\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Server stopped\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Server stopped\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Viser server on port 8080...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────── <span style=\"font-weight: bold\">viser</span> ────────────────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8080   │\n",
       "│   Websocket │ ws://localhost:8080     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────── \u001b[1mviser\u001b[0m ────────────────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8080   │\n",
       "│   Websocket │ ws://localhost:8080     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server started successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection opened <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total<span style=\"font-weight: bold\">)</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> persistent messages\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection opened \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m total\u001b[1m)\u001b[0m, \u001b[1;36m5\u001b[0m persistent messages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Create Viser Server (run once)\n",
    "import viser\n",
    "\n",
    "# Check if server already exists and stop it\n",
    "try:\n",
    "    if 'viser_server' in globals() and viser_server is not None:\n",
    "        print(\"Stopping existing server...\")\n",
    "        viser_server.stop()\n",
    "        del viser_server\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create new server\n",
    "print(\"Creating new Viser server on port 8080...\")\n",
    "viser_server = viser.ViserServer(port=8080)\n",
    "print(\"Server started successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.        4.5181384]\n",
      "[-0.01231252  0.          4.3302855 ]\n",
      "[-0.04914462  0.          4.144848  ]\n",
      "[-0.11018064  0.          3.964223  ]\n",
      "[-0.19489671  0.          3.7907739 ]\n",
      "[-0.30256417  0.          3.6268132 ]\n",
      "[-0.4322542  0.         3.4745846]\n",
      "[-0.5828438  0.         3.3362482]\n",
      "[-0.7530231  0.         3.2138643]\n",
      "[-0.94130373  0.          3.1093779 ]\n",
      "[-1.1460285  0.         3.0246048]\n",
      "[-1.3653822  0.         2.9612184]\n",
      "[-1.5974033  0.         2.9207354]\n",
      "[-1.8399963  0.         2.9045048]\n",
      "[-2.090947   0.         2.9136984]\n",
      "[-2.3479345  0.         2.9492989]\n",
      "[-2.6085486  0.         3.0120924]\n",
      "[-2.870305   0.         3.1026607]\n",
      "[-3.130662   0.         3.2213757]\n",
      "[-3.387036   0.         3.3683944]\n",
      "[-3.6368222  0.         3.5436547]\n",
      "[-3.8774083  0.         3.7468739]\n",
      "[-4.1061945  0.         3.9775474]\n",
      "[-4.320612  0.        4.23495 ]\n",
      "[-4.5181384  0.         4.5181384]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Animated Viser Content\n",
    "def setup_viser_scene(server, scene_data):\n",
    "    \"\"\"Setup static scene elements (trajectory and camera poses)\"\"\"\n",
    "\n",
    "    poses_np = scene_data['pose_target'].cpu().numpy()\n",
    "    positions = poses_np[:, :3, 3]\n",
    "    \n",
    "    # Add trajectory (static)\n",
    "    server.scene.add_spline_catmull_rom(\n",
    "        \"/trajectory\", \n",
    "        positions=positions, \n",
    "        color=(1.0, 0.0, 0.0), \n",
    "        line_width=3.0\n",
    "    )\n",
    "    \n",
    "    # Add all camera poses (static)\n",
    "    for i, pose in enumerate(poses_np[::2]):  # Every 2nd pose to reduce clutter\n",
    "        position = pose[:3, 3]\n",
    "        rotation_matrix = pose[:3, :3]\n",
    "        \n",
    "        print(position)\n",
    "        \n",
    "        # flip_z = np.array([[-1, 0, 0], [0, 1, 0], [0, 0, -1]])\n",
    "        # corrected_rotation = rotation_matrix @ flip_z\n",
    "        \n",
    "        corrected_rotation = rotation_matrix  # No correction\n",
    "        wxyz = viser.transforms.SO3.from_matrix(corrected_rotation).wxyz\n",
    "        \n",
    "        server.scene.add_camera_frustum(\n",
    "            f\"/camera_{i}\",\n",
    "            fov=60, aspect=16/9, scale=0.15,\n",
    "            position=position, wxyz=wxyz,\n",
    "            color=(0.8, 0.2, 0.2)\n",
    "        )\n",
    "    \n",
    "    # Add start/end markers\n",
    "    server.scene.add_icosphere(\"/start\", radius=0.1, position=positions[0], color=(0.0, 1.0, 0.0))\n",
    "    server.scene.add_icosphere(\"/end\", radius=0.1, position=positions[-1], color=(1.0, 0.0, 1.0))\n",
    "    server.scene.add_frame(\"/world\", axes_length=0.5, position=(0, 0, 0), wxyz=(1, 0, 0, 0))\n",
    "\n",
    "def animate_frame(server, scene_data, frame_idx, max_points=5000):\n",
    "    \"\"\"Update only the point cloud for given frame\"\"\"\n",
    "    # Clear previous frame\n",
    "    try:\n",
    "        server.scene.remove(\"/current_frame\")\n",
    "        server.scene.remove(\"/current_camera\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Extract points for this frame\n",
    "    frame_data = {\n",
    "        'frame': scene_data['frames_tensor'][frame_idx:frame_idx+1],\n",
    "        'depth': scene_data['depths'][frame_idx:frame_idx+1], \n",
    "        'pose_source': scene_data['pose_source'][frame_idx:frame_idx+1],\n",
    "        'intrinsics': scene_data['intrinsics'][frame_idx:frame_idx+1],\n",
    "    }\n",
    "    \n",
    "    points_3d, colors_rgb = vis_warper.extract_3d_points_with_colors(\n",
    "        frame_data['frame'], frame_data['depth'], \n",
    "        frame_data['pose_source'], frame_data['intrinsics'],\n",
    "        subsample_step=15\n",
    "    )\n",
    "    \n",
    "    if points_3d.shape[0] > 0:\n",
    "        points_np = points_3d.cpu().numpy()\n",
    "        colors_np = colors_rgb.cpu().numpy()\n",
    "        \n",
    "        # Limit points\n",
    "        if len(points_np) > max_points:\n",
    "            indices = np.random.choice(len(points_np), max_points, replace=False)\n",
    "            points_np = points_np[indices]\n",
    "            colors_np = colors_np[indices]\n",
    "        \n",
    "        if colors_np.min() < 0:\n",
    "            colors_np = (colors_np + 1) / 2\n",
    "            \n",
    "        # Update point cloud\n",
    "        server.scene.add_point_cloud(\n",
    "            \"/current_frame\", \n",
    "            points=points_np, \n",
    "            colors=colors_np, \n",
    "            point_size=0.03\n",
    "        )\n",
    "        \n",
    "        # Highlight current camera\n",
    "        pos = scene_data['pose_target'][frame_idx, :3, 3].cpu().numpy()\n",
    "        server.scene.add_icosphere(\n",
    "            \"/current_camera\", \n",
    "            radius=0.08, \n",
    "            position=pos, \n",
    "            color=(1.0, 1.0, 0.0)  # Yellow\n",
    "        )\n",
    "\n",
    "# Setup scene\n",
    "setup_viser_scene(viser_server, scene_data)\n",
    "\n",
    "# Create GUI controls for animation\n",
    "@viser_server.on_client_connect\n",
    "def _(client: viser.ClientHandle) -> None:\n",
    "    # Animation controls\n",
    "    play_button = client.gui.add_button(\"Play/Pause\")\n",
    "    frame_slider = client.gui.add_slider(\n",
    "        \"Frame\", \n",
    "        min=0, \n",
    "        max=scene_data['frames_tensor'].shape[0]-1, \n",
    "        step=1, \n",
    "        initial_value=0\n",
    "    )\n",
    "    speed_slider = client.gui.add_slider(\n",
    "        \"Speed\", \n",
    "        min=1, \n",
    "        max=10.0, \n",
    "        step=0.1, \n",
    "        initial_value=3.0\n",
    "    )\n",
    "    \n",
    "    # Animation state\n",
    "    is_playing = [False]\n",
    "    \n",
    "    @play_button.on_click\n",
    "    def _(_):\n",
    "        is_playing[0] = not is_playing[0]\n",
    "        \n",
    "    @frame_slider.on_update\n",
    "    def _(_):\n",
    "        animate_frame(viser_server, scene_data, frame_slider.value)\n",
    "    \n",
    "    # Animation loop\n",
    "    import threading\n",
    "    import time\n",
    "    \n",
    "    def animation_loop():\n",
    "        while True:\n",
    "            if is_playing[0]:\n",
    "                current_frame = frame_slider.value\n",
    "                next_frame = (current_frame + 1) % scene_data['frames_tensor'].shape[0]\n",
    "                frame_slider.value = next_frame\n",
    "                animate_frame(viser_server, scene_data, next_frame)\n",
    "            time.sleep(0.5 / speed_slider.value)\n",
    "    \n",
    "    # Start animation thread\n",
    "    animation_thread = threading.Thread(target=animation_loop, daemon=True)\n",
    "    animation_thread.start()\n",
    "\n",
    "# Show first frame\n",
    "animate_frame(viser_server, scene_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Viser GUI Controls\n",
    "##########################################\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import viser\n",
    "\n",
    "\n",
    "# Simple Point Size Control\n",
    "@viser_server.on_client_connect\n",
    "def _(client: viser.ClientHandle) -> None:\n",
    "    \n",
    "    update_camera_position()\n",
    "    \n",
    "    # Add simple point size slider\n",
    "    point_size_slider = client.gui.add_slider(\n",
    "        \"Point Size\",\n",
    "        min=0.005,\n",
    "        max=0.1,\n",
    "        step=0.005,\n",
    "        initial_value=0.015,\n",
    "    )\n",
    "    \n",
    "    # Update point size when slider changes\n",
    "    @point_size_slider.on_update\n",
    "    def _(_) -> None:\n",
    "        if points_3d is not None:\n",
    "            points_np = points_3d.cpu().numpy()\n",
    "            colors_np = colors_rgb.cpu().numpy()\n",
    "            if colors_np.min() < 0:\n",
    "                colors_np = (colors_np + 1) / 2\n",
    "            viser_server.scene.add_point_cloud(\n",
    "                \"/scene_points\",\n",
    "                points=points_np,\n",
    "                colors=colors_np,\n",
    "                point_size=point_size_slider.value\n",
    "            )\n",
    "\n",
    "# Set initial camera position\n",
    "initial_theta = 0\n",
    "initial_phi = 75\n",
    "initial_roll = -90\n",
    "initial_radius = 10\n",
    "\n",
    "# Add sliders for camera control (no global variables needed)\n",
    "theta_slider = viser_server.gui.add_slider(\n",
    "    \"Camera Theta (deg)\",\n",
    "    min=0, max=360, step=1, initial_value=initial_theta,\n",
    ")\n",
    "\n",
    "phi_slider = viser_server.gui.add_slider(\n",
    "    \"Camera Phi (deg)\", \n",
    "    min=-90, max=270, step=1, initial_value=initial_phi,\n",
    ")\n",
    "\n",
    "roll_slider = viser_server.gui.add_slider(\n",
    "    \"Camera Roll (deg)\",\n",
    "    min=-180, max=180, step=1, initial_value=initial_roll,\n",
    ")\n",
    "\n",
    "radius_slider = viser_server.gui.add_slider(\n",
    "    \"Camera Distance\",\n",
    "    min=1, max=20, step=0.1, initial_value=initial_radius,\n",
    ")\n",
    "\n",
    "def update_camera_position():\n",
    "    theta = math.radians(theta_slider.value)\n",
    "    phi = math.radians(phi_slider.value)\n",
    "    r = radius_slider.value\n",
    "    roll = math.radians(roll_slider.value)\n",
    "    \n",
    "    # Convert spherical to cartesian\n",
    "    x = r * math.cos(phi) * math.cos(theta)\n",
    "    y = r * math.cos(phi) * math.sin(theta) \n",
    "    z = r * math.sin(phi)\n",
    "    \n",
    "    position = np.array([x, y, z])\n",
    "    look_at = np.array([0, 0, 0])\n",
    "    \n",
    "    # Calculate camera's forward direction\n",
    "    forward = (look_at - position)\n",
    "    forward = forward / np.linalg.norm(forward)\n",
    "    \n",
    "    # Handle world up vector based on phi angle to prevent flipping\n",
    "    if abs(phi) < math.pi/2:  # -90° to +90°: normal \"above horizon\" view\n",
    "        world_up = np.array([0, 0, 1])\n",
    "    else:  # Beyond ±90°: \"below horizon\" or \"upside down\" view\n",
    "        world_up = np.array([0, 0, -1])  # Flip world up\n",
    "    \n",
    "    # Calculate right vector\n",
    "    right = np.cross(forward, world_up)\n",
    "    if np.linalg.norm(right) < 1e-6:  # Handle gimbal lock at poles\n",
    "        # Use a fallback right vector\n",
    "        right = np.array([1, 0, 0]) if abs(theta) < math.pi else np.array([-1, 0, 0])\n",
    "    else:\n",
    "        right = right / np.linalg.norm(right)\n",
    "    \n",
    "    # Calculate up vector\n",
    "    up_initial = np.cross(right, forward)\n",
    "    up_initial = up_initial / np.linalg.norm(up_initial)\n",
    "    \n",
    "    # Apply roll rotation around the forward axis\n",
    "    cos_roll = np.cos(roll)\n",
    "    sin_roll = np.sin(roll)\n",
    "    up = cos_roll * up_initial + sin_roll * right\n",
    "    \n",
    "    # Set camera using the correct API\n",
    "    for client in viser_server.get_clients().values():\n",
    "        client.camera.position = position\n",
    "        client.camera.look_at = look_at\n",
    "        client.camera.up_direction = up\n",
    "        \n",
    "\n",
    "@theta_slider.on_update\n",
    "def _(_):\n",
    "    update_camera_position()\n",
    "    \n",
    "@phi_slider.on_update \n",
    "def _(_):\n",
    "    update_camera_position()\n",
    "    \n",
    "@radius_slider.on_update\n",
    "def _(_):\n",
    "    update_camera_position()\n",
    "\n",
    "@roll_slider.on_update\n",
    "def _(_):\n",
    "    update_camera_position()\n",
    "\n",
    "# Apply initial camera position\n",
    "# update_camera_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: To test different trajectories (example)\n",
    "# Change your trajectory and re-run the update\n",
    "opts_test = copy.deepcopy(opts_base)\n",
    "opts_test.target_pose = [0, 90, 1, 0, 0]  # 180° rotation\n",
    "\n",
    "# Generate new scene data\n",
    "scene_data_test = vis_crafter.extract_scene_data(opts_test)\n",
    "\n",
    "# Update the same server with new content\n",
    "update_viser_content(viser_server, scene_data_test, points_3d, colors_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Camera trajectory visualization\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading video frames...\n",
      "==> processing video:  ./test/videos/0-NNvgaTcVzAG0-r.mp4\n",
      "==> original video shape:  (146, 720, 1280, 3)\n",
      "==> downsampled shape: (146, 576, 1024, 3), with stride: 1\n",
      "==> final processing shape: (49, 576, 1024, 3)\n",
      "Estimating depth...\n",
      "Elapsed time for encoding video: 9381.609375 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dac0bc0e837435da37cc88685754ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for denoising video: 20547.40234375 ms\n",
      "Elapsed time for decoding video: 17704.69921875 ms\n",
      "Converting frames to tensors...\n",
      "Generating camera poses...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection closed <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> total<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection closed \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m total\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract scene data (same as your existing code)\n",
    "scene_data = vis_crafter.extract_scene_data(opts_base)\n",
    "\n",
    "# Generate CIRCULAR trajectory instead of linear\n",
    "def generate_circular_scene_data(crafter, opts, scene_data, circle_type='horizontal'):\n",
    "    \"\"\"Generate new scene data with circular motion\"\"\"\n",
    "    \n",
    "    # Reuse existing depths and frames\n",
    "    pose_s, pose_t, K = crafter.get_poses_circular(\n",
    "        opts, \n",
    "        scene_data['depths'], \n",
    "        num_frames=opts.video_length,\n",
    "        circle_type=circle_type\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'frames_numpy': scene_data['frames_numpy'],\n",
    "        'frames_tensor': scene_data['frames_tensor'],\n",
    "        'depths': scene_data['depths'], \n",
    "        'pose_source': pose_s,\n",
    "        'pose_target': pose_t,\n",
    "        'intrinsics': K,\n",
    "        'radius': scene_data['radius'],\n",
    "        'trajectory_params': f\"circular_{circle_type}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circular trajectories generated!\n",
      "Available types: horizontal, vertical_xz, vertical_yz, tilted\n"
     ]
    }
   ],
   "source": [
    "# Generate different circular motions\n",
    "# horizontal_circle = generate_circular_scene_data(vis_crafter, opts_base, scene_data, 'horizontal')\n",
    "vertical_circle = generate_circular_scene_data(vis_crafter, opts_base, scene_data, 'vertical_xz')\n",
    "\n",
    "# Use in your existing Viser visualization\n",
    "# update_trajectory_visualization(viser_server, horizontal_circle)\n",
    "update_trajectory_visualization(viser_server, vertical_circle)\n",
    "\n",
    "print(\"Circular trajectories generated!\")\n",
    "print(\"Available types: horizontal, vertical_xz, vertical_yz, tilted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory visualization setup complete!\n",
      "Available presets: ['Original Right 90°', 'Left 90°', 'Full Circle', 'Up and Right', 'Pull Back', 'Orbit Up', 'Dolly Forward', 'Rise and Turn']\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# Camera trajectory visualization - Multiple Trajectories\n",
    "##########################################################################\n",
    "\n",
    "def generate_new_trajectory(vis_crafter, opts_base, target_pose_params, scene_data):\n",
    "    \"\"\"Generate new trajectory without recomputing point clouds\"\"\"\n",
    "    print(f\"Generating trajectory for pose: {target_pose_params}\")\n",
    "    \n",
    "    # Create new opts with different target pose\n",
    "    opts_new = copy.deepcopy(opts_base)\n",
    "    opts_new.target_pose = target_pose_params\n",
    "    \n",
    "    # Only regenerate poses, reuse existing depths\n",
    "    # pose_s, pose_t, K = vis_crafter.get_poses(opts_new, scene_data['depths'], num_frames=opts_new.video_length)\n",
    "    pose_s, pose_t, K = vis_crafter.get_poses_circular(\n",
    "        opts_new, \n",
    "        scene_data['depths'], \n",
    "        num_frames=opts_new.video_length,\n",
    "        circle_type='horizontal'  # or other types based on params\n",
    "    )\n",
    "    \n",
    "    # Create new scene data with same point clouds but new trajectory\n",
    "    new_scene_data = {\n",
    "        'frames_numpy': scene_data['frames_numpy'],\n",
    "        'frames_tensor': scene_data['frames_tensor'], \n",
    "        'depths': scene_data['depths'],\n",
    "        'pose_source': pose_s,\n",
    "        'pose_target': pose_t,\n",
    "        'intrinsics': K,\n",
    "        'radius': scene_data['radius'],\n",
    "        'trajectory_params': target_pose_params\n",
    "    }\n",
    "    \n",
    "    return new_scene_data\n",
    "\n",
    "def update_trajectory_visualization(server, new_scene_data):\n",
    "    \"\"\"Update only the trajectory visualization, keep point clouds\"\"\"\n",
    "    \n",
    "    # Clear existing trajectory elements\n",
    "    try:\n",
    "        server.scene.remove(\"/trajectory\")\n",
    "        for i in range(50):  # Clear up to 50 camera poses\n",
    "            try:\n",
    "                server.scene.remove(f\"/camera_{i}\")\n",
    "            except:\n",
    "                break\n",
    "        server.scene.remove(\"/start\")\n",
    "        server.scene.remove(\"/end\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Add new trajectory\n",
    "    poses_np = new_scene_data['pose_target'].cpu().numpy()\n",
    "    positions = poses_np[:, :3, 3]\n",
    "    \n",
    "    # Add trajectory spline\n",
    "    server.scene.add_spline_catmull_rom(\n",
    "        \"/trajectory\", \n",
    "        positions=positions, \n",
    "        color=(1.0, 0.0, 0.0), \n",
    "        line_width=3.0\n",
    "    )\n",
    "    \n",
    "    # Add camera poses (every 2nd to reduce clutter)\n",
    "    for i, pose in enumerate(poses_np[::2]):\n",
    "        position = pose[:3, 3]\n",
    "        rotation_matrix = pose[:3, :3]\n",
    "        \n",
    "        # flip_z = np.array([[-1, 0, 0], [0, 1, 0], [0, 0, -1]])\n",
    "        # corrected_rotation = rotation_matrix @ flip_z\n",
    "        \n",
    "        corrected_rotation = rotation_matrix  # No correction\n",
    "        wxyz = viser.transforms.SO3.from_matrix(corrected_rotation).wxyz\n",
    "        \n",
    "        server.scene.add_camera_frustum(\n",
    "            f\"/camera_{i}\",\n",
    "            fov=60, aspect=16/9, scale=0.15,\n",
    "            position=position, wxyz=wxyz,\n",
    "            color=(0.8, 0.2, 0.2)\n",
    "        )\n",
    "    \n",
    "    # Add new start/end markers\n",
    "    server.scene.add_icosphere(\"/start\", radius=0.1, position=positions[0], color=(0.0, 1.0, 0.0))\n",
    "    server.scene.add_icosphere(\"/end\", radius=0.1, position=positions[-1], color=(1.0, 0.0, 1.0))\n",
    "\n",
    "# Predefined trajectory presets\n",
    "TRAJECTORY_PRESETS = {\n",
    "    \"Original Right 90°\": [0, 90, 1, 0, 0],\n",
    "    \"Left 90°\": [0, -90, 1, 0, 0], \n",
    "    \"Full Circle\": [0, 360, 1, 0, 0],\n",
    "    \"Up and Right\": [45, 45, 0.5, 0, 1],\n",
    "    \"Pull Back\": [0, 0, 3, 0, 0],\n",
    "    \"Orbit Up\": [30, 180, 0, 0, 0],\n",
    "    \"Dolly Forward\": [0, 0, -2, 0, 0],\n",
    "    \"Rise and Turn\": [60, 120, 1, 0, 2],\n",
    "}\n",
    "\n",
    "# Create trajectory selection GUI\n",
    "@viser_server.on_client_connect  \n",
    "def _(client: viser.ClientHandle) -> None:\n",
    "    \n",
    "    # Trajectory selection dropdown\n",
    "    trajectory_dropdown = client.gui.add_dropdown(\n",
    "        \"Trajectory Preset\",\n",
    "        options=list(TRAJECTORY_PRESETS.keys()),\n",
    "        initial_value=\"Original Right 90°\"\n",
    "    )\n",
    "    \n",
    "    # Manual trajectory controls\n",
    "    with client.gui.add_folder(\"Custom Trajectory\"):\n",
    "        theta_input = client.gui.add_slider(\"Theta (pitch)\", min=-90, max=90, step=1, initial_value=0)\n",
    "        phi_input = client.gui.add_slider(\"Phi (yaw)\", min=-360, max=360, step=5, initial_value=90)\n",
    "        dr_input = client.gui.add_slider(\"Distance\", min=-3, max=3, step=0.1, initial_value=1.0)\n",
    "        dx_input = client.gui.add_slider(\"X offset\", min=-2, max=2, step=0.1, initial_value=0.0)\n",
    "        dy_input = client.gui.add_slider(\"Y offset\", min=-2, max=2, step=0.1, initial_value=0.0)\n",
    "        \n",
    "        generate_button = client.gui.add_button(\"Generate Custom Trajectory\")\n",
    "    \n",
    "    # Display current trajectory info\n",
    "    trajectory_info = client.gui.add_text(\"Trajectory Info\", initial_value=\"Current: [0, 90, 1, 0, 0]\")\n",
    "    \n",
    "    # Global reference to current scene data\n",
    "    current_scene_data = [scene_data]  # Use list for mutability\n",
    "    \n",
    "    @trajectory_dropdown.on_update\n",
    "    def _(_):\n",
    "        selected_preset = trajectory_dropdown.value\n",
    "        target_pose = TRAJECTORY_PRESETS[selected_preset]\n",
    "        \n",
    "        # Generate new trajectory\n",
    "        new_scene_data = generate_new_trajectory(vis_crafter, opts_base, target_pose, scene_data)\n",
    "        current_scene_data[0] = new_scene_data\n",
    "        \n",
    "        # Update visualization\n",
    "        update_trajectory_visualization(viser_server, new_scene_data)\n",
    "        \n",
    "        # Update info\n",
    "        trajectory_info.value = f\"Current: {target_pose}\"\n",
    "        \n",
    "        # Update manual controls to match preset\n",
    "        theta_input.value = target_pose[0]\n",
    "        phi_input.value = target_pose[1] \n",
    "        dr_input.value = target_pose[2]\n",
    "        dx_input.value = target_pose[3]\n",
    "        dy_input.value = target_pose[4]\n",
    "        \n",
    "        print(f\"Switched to trajectory: {selected_preset} -> {target_pose}\")\n",
    "    \n",
    "    @generate_button.on_click\n",
    "    def _(_):\n",
    "        custom_pose = [theta_input.value, phi_input.value, dr_input.value, dx_input.value, dy_input.value]\n",
    "        \n",
    "        # Generate new trajectory\n",
    "        new_scene_data = generate_new_trajectory(vis_crafter, opts_base, custom_pose, scene_data)\n",
    "        current_scene_data[0] = new_scene_data\n",
    "        \n",
    "        # Update visualization  \n",
    "        update_trajectory_visualization(viser_server, new_scene_data)\n",
    "        \n",
    "        # Update info\n",
    "        trajectory_info.value = f\"Current: {custom_pose}\"\n",
    "        \n",
    "        print(f\"Generated custom trajectory: {custom_pose}\")\n",
    "    \n",
    "    # Animation controls for current trajectory\n",
    "    with client.gui.add_folder(\"Animation\"):\n",
    "        play_button = client.gui.add_button(\"Play/Pause\")\n",
    "        frame_slider = client.gui.add_slider(\n",
    "            \"Frame\", \n",
    "            min=0, \n",
    "            max=scene_data['frames_tensor'].shape[0]-1, \n",
    "            step=1, \n",
    "            initial_value=0\n",
    "        )\n",
    "        speed_slider = client.gui.add_slider(\"Speed\", min=0.5, max=5.0, step=0.1, initial_value=1.0)\n",
    "    \n",
    "    # Animation state\n",
    "    is_playing = [False]\n",
    "    \n",
    "    @play_button.on_click\n",
    "    def _(_):\n",
    "        is_playing[0] = not is_playing[0]\n",
    "        \n",
    "    @frame_slider.on_update\n",
    "    def _(_):\n",
    "        animate_frame(viser_server, current_scene_data[0], frame_slider.value)\n",
    "    \n",
    "    # Animation loop\n",
    "    import threading\n",
    "    import time\n",
    "    \n",
    "    def animation_loop():\n",
    "        while True:\n",
    "            if is_playing[0]:\n",
    "                current_frame = frame_slider.value\n",
    "                next_frame = (current_frame + 1) % current_scene_data[0]['frames_tensor'].shape[0]\n",
    "                frame_slider.value = next_frame\n",
    "                animate_frame(viser_server, current_scene_data[0], next_frame)\n",
    "            time.sleep(1.0 / speed_slider.value)\n",
    "    \n",
    "    # Start animation thread\n",
    "    animation_thread = threading.Thread(target=animation_loop, daemon=True)\n",
    "    animation_thread.start()\n",
    "\n",
    "print(\"Trajectory visualization setup complete!\")\n",
    "print(\"Available presets:\", list(TRAJECTORY_PRESETS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating trajectory for pose: [0, 90, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Generate and print trajectory numbers for a few presets\n",
    "target_poses = {\n",
    "    \"Right 90°\": [0, 90, 1, 0, 0],\n",
    "    \"Full Circle\": [0, 360, 1, 0, 0],\n",
    "    \"Pull Back\": [0, 0, 3, 0, 0]\n",
    "}\n",
    "\n",
    "new_data = generate_new_trajectory(\n",
    "    vis_crafter, opts_base,\n",
    "    target_poses[\"Right 90°\"],\n",
    "    scene_data\n",
    "    )\n",
    "\n",
    "positions = new_data['pose_target'].cpu().numpy()[:, :3, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory shape: (49, 3)\n",
      "X range: -4.509 to 4.518\n",
      "Z range: 4.518 to 4.518\n",
      "Start (X,Z): (4.518, 4.518)\n",
      "End (X,Z): (4.481, 4.518)\n"
     ]
    }
   ],
   "source": [
    "# using maplotlib, plot the 0th and 2rd axis\n",
    "# Using matplotlib, plot the 0th and 2nd axis of positions variable\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot X vs Z (0th vs 2nd axis)\n",
    "plt.plot(positions[:, 0], positions[:, 2], 'b-o', linewidth=2, markersize=4)\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Z Position') \n",
    "plt.title('Camera Trajectory: X vs Z (Top-down view)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "\n",
    "# Mark start and end points\n",
    "plt.plot(positions[0, 0], positions[0, 2], 'go', markersize=10, label='Start')\n",
    "plt.plot(positions[-1, 0], positions[-1, 2], 'ro', markersize=10, label='End')\n",
    "\n",
    "# Add frame numbers for reference\n",
    "for i in range(0, len(positions), max(1, len(positions)//8)):\n",
    "    plt.annotate(f'{i}', (positions[i, 0], positions[i, 2]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the trajectory values\n",
    "print(f\"Trajectory shape: {positions.shape}\")\n",
    "print(f\"X range: {positions[:, 0].min():.3f} to {positions[:, 0].max():.3f}\")\n",
    "print(f\"Z range: {positions[:, 2].min():.3f} to {positions[:, 2].max():.3f}\")\n",
    "print(f\"Start (X,Z): ({positions[0, 0]:.3f}, {positions[0, 2]:.3f})\")\n",
    "print(f\"End (X,Z): ({positions[-1, 0]:.3f}, {positions[-1, 2]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (49, 4, 4)\n",
      "\n",
      "First pose (Frame 0):\n",
      "[[-1.         0.         0.         0.       ]\n",
      " [ 0.         1.         0.         0.       ]\n",
      " [ 0.         0.        -1.         4.5181384]\n",
      " [ 0.         0.         0.         1.       ]]\n",
      "\n",
      "Position: [0.        0.        4.5181384]\n",
      "Rotation matrix:\n",
      "[[-1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0. -1.]]\n",
      "\n",
      "Coordinate system analysis:\n",
      "Z-axis (forward direction): [ 0.  0. -1.]\n",
      "Y-axis (up direction): [0. 1. 0.]\n",
      "X-axis (right direction): [-1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Check the coordinate system by examining a few poses\n",
    "poses = new_data['pose_target'].cpu().numpy()\n",
    "print(\"Shape:\", poses.shape)\n",
    "print(\"\\nFirst pose (Frame 0):\")\n",
    "print(poses[0])\n",
    "print(\"\\nPosition:\", poses[0][:3, 3])\n",
    "print(\"Rotation matrix:\")\n",
    "print(poses[0][:3, :3])\n",
    "\n",
    "# Check if it follows OpenCV or OpenGL convention\n",
    "print(\"\\nCoordinate system analysis:\")\n",
    "print(\"Z-axis (forward direction):\", poses[0][:3, 2])\n",
    "print(\"Y-axis (up direction):\", poses[0][:3, 1]) \n",
    "print(\"X-axis (right direction):\", poses[0][:3, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
